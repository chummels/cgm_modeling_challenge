{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Mock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load using my preferred wrapper for hdf5 files.\n",
    "data = verdict.Dict.from_hdf5( './data/synthetic_data/sample{}/observers_file.h5'.format( sample_number ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign Errors\n",
    "\n",
    "Our goal is to create semi-realistic errors.\n",
    "We won't put too much effort into this, so we'll roughly fit a gamma function to the distribution of errors from COS-Halos data, and sample from the distribution.\n",
    "We do provide a bound on 1.5 the maximum observed error, however, to prevent getting anything too crazy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive Errors from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_fwf(\n",
    "    './data/cos_halos_data.txt',\n",
    "    skiprows = 31,\n",
    "    names = [ 'ID', 'z', 'Ion', 'Vel', 'e_Vel', 'b', 'e_b', 'logN', 'elogN', 'l_logNA', ',logNA', 'e_logNA' ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ions used\n",
    "ions = list( set( df['Ion'] ) )\n",
    "ions.remove( np.nan )\n",
    "ions.append( 'H I' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get out errors from data, mildly processed\n",
    "elogNs = {}\n",
    "for ion in ions:\n",
    "        \n",
    "    if ion != 'H I':\n",
    "        # Locate\n",
    "        ion_df = df[df['Ion'] == ion]\n",
    "        elogN = []\n",
    "        for e in ion_df['elogN'].values:\n",
    "            try:\n",
    "                elogN.append( float( e ) )\n",
    "            except ValueError:\n",
    "                continue\n",
    "    else:\n",
    "        # Manual H I input from COS-Halos hydrogen paper\n",
    "        elogN = [ 0.03, 0.05, 0.05, 0.03, 0.09, 0.03, 0.15, 0.15, 0.08, 0.06, 0.03, 0.06, 0.03, 0.04, 0.03, 0.13, 0.06, 0.04, 0.05, 0.06, 0.02, 0.04, 0.06, 0.04, 0.04, 0.03, 0.07, 0.06, 0.10, 0.12, 0.06, 0.02, 0.03, 0.09, 0.04, 0.03, 0.04, ]\n",
    "\n",
    "    elogNs[ion] = np.array( elogN )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats of the errors\n",
    "\n",
    "errs = {}\n",
    "for ion in ions:\n",
    "    \n",
    "    elogN = elogNs[ion]\n",
    "\n",
    "    # Extract\n",
    "    errs[ion] = {\n",
    "        'mean': np.mean( elogN ),\n",
    "        'std': np.std( elogN ),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Create a gamma fn, *very* roughly fitted\n",
    "    beta = errs[ion]['mean'] / errs[ion]['std']\n",
    "    alpha = errs[ion]['mean'] * beta\n",
    "    dist = scipy.stats.gamma( a=alpha, scale=1/beta  )\n",
    "    \n",
    "    # Plot and store\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    ax.hist(\n",
    "        elogN,\n",
    "        bins = np.linspace( 0, elogN.max(), 32 )\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.linspace( 0, elogN.max(), 128 ),\n",
    "        dist.pdf( np.linspace( 0, elogN.max(), 128 ) ),\n",
    "    )\n",
    "    ax.annotate(\n",
    "        s = ion,\n",
    "        xy = ( 1, 1 ),\n",
    "        xytext = ( -5, -5 ),\n",
    "        va = 'top',\n",
    "        ha = 'right',\n",
    "        xycoords = 'axes fraction',\n",
    "        textcoords = 'offset points',\n",
    "        fontsize = 20,\n",
    "    )\n",
    "    errs[ion]['dist'] = dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = {}\n",
    "for ion in data.keys():\n",
    "    \n",
    "    dist = errs[ion]['dist']\n",
    "    \n",
    "    ion_errs = []\n",
    "    modified_columns = []\n",
    "    for i, column in enumerate( data[ion] ):\n",
    "        \n",
    "        ion_err = np.inf\n",
    "        while ( ion_err > elogNs[ion].max()*1.5 ) or ( ion_err < elogNs[ion].min() / 1.5 ):\n",
    "            ion_err = dist.rvs()\n",
    "            \n",
    "        # Assume error is conservative, apply\n",
    "        modified_column = column * 10.**np.random.uniform( -ion_err, ion_err )\n",
    "        \n",
    "        # Round and store\n",
    "        ion_errs.append( np.round( ion_err, decimals=3 ) )\n",
    "        modified_columns.append( np.round( np.log10( modified_column ), decimals=3 ) )\n",
    "        \n",
    "    data_out[ion] = {\n",
    "        'logN': np.array( modified_columns ),\n",
    "        'elogN': np.array( ion_errs ),\n",
    "    }\n",
    "data_out = verdict.Dict( data_out )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out.to_hdf5( './data/sample{}.h5'.format( sample_number ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload for Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = verdict.Dict.from_hdf5( './data/synthetic_data_samples/sample{}.h5'.format( sample_number ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
