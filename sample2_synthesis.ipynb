{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc1b6d-4adb-4157-87a3-03622632e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fed0f2-7d47-4955-ac25-640d09f77aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import trident\n",
    "import unyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc0084-d12d-45ad-a209-d9078dd8f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kalepy as kale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f22441-2234-40ec-baae-ebe1edd862e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trove\n",
    "import verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1af51-24eb-47a0-aadf-175ecdcbd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Currently need to call this to get matplotlib selected style to load...\n",
    "plt.plot()\n",
    "matplotlib.style.use( '/Users/zhafen/repos/clean-bold/clean-bold.mplstyle' )\n",
    "import palettable\n",
    "import matplotlib.patheffects as path_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb0fd2-1b28-4f48-ba5b-c8a24a134c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f085e-92e7-4860-a9a8-7c038bef9947",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb637a3-81dd-4abb-a1ed-a13f18c8fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "variations = [ \n",
    "    'original',\n",
    "    'high-z',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede9ac4-52f5-4e59-9eeb-b720128fc41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Analysis \n",
    "    'prop_keys': [ 'vlos', 'T', 'nH', 'Z' ],\n",
    "    'vel_prop_keys': [ 'vlos', 'T', 'nH', 'Z', 'NHI' ],\n",
    "    'broaden_models': True,\n",
    "    '1D_dist_estimation': 'kde',\n",
    "    '1D_dist_estimation_data': 'histogram',\n",
    "    '2D_dist_estimation': 'histogram',\n",
    "    'export_data_for_proposal': False,\n",
    "    'f_enclosed': [ 0.5, 0.75, 0.9, 0.99 ],\n",
    "    \n",
    "    # Plotting Choices\n",
    "    'smooth_2D_dist': 0.5,\n",
    "    'upsample_2D_dist': 3,\n",
    "    '2D_dist_data_display': 'histogram',\n",
    "    'contour_levels': [ 90, 50 ],\n",
    "    'contour_linewidths': [ 1, 3 ],\n",
    "    'show_plots_in_nb': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f4aca5-0604-4f41-bf5f-4ec87fe98db7",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b33a4f-c66e-4f93-a1ca-c369081ad97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_coefficients = {\n",
    "    'one-sided': {},\n",
    "    'log one-sided': { 'logscale': True, 'subtract_mean': True },\n",
    "    'two-sided': { 'one_sided': False, },\n",
    "    'linear': { 'one_sided': False, 'subtract_mean': True },\n",
    "    'log': { 'logscale': True, 'one_sided': False, 'subtract_mean': True },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc194a2e-881d-4afa-8f01-d5eea240f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = {\n",
    "    'vlos': [ -300, 300 ],\n",
    "    'T': [ 1e2, 2.5e6 ],\n",
    "    'nH': [ 1e-7, 100 ],\n",
    "    'Z': [ 1e-3, 30 ],\n",
    "    'NHI': [ 1e9, 1e17 ],\n",
    "}\n",
    "autolims = {\n",
    "    'vlos': False,\n",
    "    'T': False,\n",
    "    'nH': False,\n",
    "    'Z': False,\n",
    "    'NHI': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2e0cd-10e8-4d93-a75c-d1dd55ee5b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lims_1D = {\n",
    "    'vlos': [ 3e9, 2e16 ],\n",
    "    'T': [ 1e12, 1e20 ],\n",
    "    'nH': [ 1e12, 1e20 ],\n",
    "    'Z': [ 1e12, 1e20 ],\n",
    "    'NHI': [ 1e12, 1e20 ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293db0b-c166-453b-ac70-4b1b5e751125",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvs = {\n",
    "    'vlos': 5.,\n",
    "    'T': 0.05,\n",
    "    'nH': 0.05,\n",
    "    'Z': 0.05,\n",
    "    'NHI': 0.05,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0429a-4359-43f1-835d-09c099a9543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logscale = {\n",
    "    'vlos': False,\n",
    "    'T': True,\n",
    "    'nH': True,\n",
    "    'Z': True,\n",
    "    'NHI': True,\n",
    "}\n",
    "variation_colors = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d5523-475b-4166-a97a-368fd2e4593c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ecdfad-1324-4c0a-aa85-14c0827e7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_plotting_params = {\n",
    "    'original': {\n",
    "        'color': helpers.modeled_color,\n",
    "        'label': 'estimated',\n",
    "    },\n",
    "    'high-z': {\n",
    "        'color': helpers.revised_color,\n",
    "        'label': 'revised',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe053ec-3e62-4eb3-8ff2-1826bfaa8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'vlos': r'$v_{\\rm LOS}$ [km/s]',\n",
    "    'T': r'T [K]',\n",
    "    'nH': r'$n_{\\rm H}$ [cm$^{-3}$]',\n",
    "    'Z': r'$Z$ [$Z_{\\odot}$]',\n",
    "    'NHI': r'$N_{\\rm H\\,I}$ [cm$^{-2}$]',\n",
    "}\n",
    "labels_1D = {\n",
    "    'vlos': r'$\\frac{ d N_{\\rm H\\,I} }{d v_{\\rm LOS}}$',\n",
    "    'T': r'$\\frac{ d N_{\\rm H\\,I} }{d \\log T}$',\n",
    "    'nH': r'$\\frac{ d N_{\\rm H\\,I} }{d \\log n_{\\rm H}}$',\n",
    "    'Z': r'$\\frac{ d N_{\\rm H\\,I} }{d \\log Z}$',\n",
    "    'NHI': r'$\\frac{ d N_{\\rm H\\,I} }{d \\log N_{\\rm H\\,I}}$',\n",
    "}\n",
    "r_labels = {}\n",
    "for key, item in labels.items():\n",
    "    unitless_label = item.split( '[' )[0]\n",
    "    r_labels[key] = r'$r($ ' + unitless_label + r'$)$'\n",
    "r_labels['all'] = r'$r($ all $)$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd7e37-7f32-46c9-8313-73d64f78ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_markers = {\n",
    "    'one-sided': '^',\n",
    "    'log one-sided': '^',\n",
    "    'two-sided': 'D',\n",
    "    'linear': 'o',\n",
    "    'log': 'o',\n",
    "}\n",
    "correlation_sizes = {\n",
    "    'one-sided': 100,\n",
    "    'log one-sided': 100,\n",
    "    'two-sided': 80,\n",
    "    'linear': 100,\n",
    "    'log': 100,\n",
    "}\n",
    "correlations_plotted = [ 'linear', 'log' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e4170d-07c9-442f-902b-a3fe0de1c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = [\n",
    "    [ 'vlos', 'legend', '.', '.' ],\n",
    "    [ 'T_vlos', 'T', '.', '.' ],\n",
    "    [ 'nH_vlos', 'nH_T', 'nH', '.' ],\n",
    "    [ 'Z_vlos', 'Z_T', 'Z_nH', 'Z', ],\n",
    "]\n",
    "velocity_mosaic = [\n",
    "    [ 'nH_vlos', 'vlos', ],\n",
    "    [ 'Z_vlos', 'T_vlos', ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04338431-c72a-4fdb-99bc-7f0b1ec3f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_length = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7c229-5fe0-40cb-8760-bc52354aa57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = palettable.cartocolors.qualitative.Safe_10.mpl_colors\n",
    "corr_cmap = palettable.cartocolors.diverging.Temps_2_r.mpl_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85890ae-1d72-4668-82e1-ca6459cf8967",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_norm = matplotlib.colors.Normalize( vmin=0, vmax=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3186f-3044-4a63-ada9-0288422c3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_color_linear_cmap( color, name, f_white=0.95, f_saturated=1.0, ):\n",
    "    '''A function that turns a single color into linear colormap that\n",
    "    goes from a color that is whiter than the original color to a color\n",
    "    that is more saturated than the original color.\n",
    "    '''\n",
    "    \n",
    "    color_hsv = matplotlib.colors.rgb_to_hsv( color )\n",
    "    start_color_hsv = copy.copy( color_hsv )\n",
    "    \n",
    "    start_color_hsv = copy.copy( color_hsv )\n",
    "    start_color_hsv[1] -= f_white * start_color_hsv[1]\n",
    "    start_color_hsv[2] += f_white * ( 1. - start_color_hsv[2] )\n",
    "    start_color = matplotlib.colors.hsv_to_rgb( start_color_hsv )\n",
    "    \n",
    "    end_color_hsv = copy.copy( color_hsv )\n",
    "    end_color_hsv[1] += f_saturated * ( 1. - end_color_hsv[1] )\n",
    "    end_color = matplotlib.colors.hsv_to_rgb( end_color_hsv )\n",
    "    \n",
    "    return matplotlib.colors.LinearSegmentedColormap.from_list( name, [ start_color, end_color ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e4210-7fdf-4d0e-b3fb-2c4771a3f153",
   "metadata": {},
   "source": [
    "## Process analysis parameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b938d2a-72bf-4f17-8534-3379712e2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "pms = {}\n",
    "for variation in variations:\n",
    "    pm = trove.link_params_to_config(\n",
    "        '/Users/zhafen/analysis/cgm_modeling_challenge/sample2.trove',\n",
    "        script_id = 'nb.2',\n",
    "        variation = variation,\n",
    "        global_variation = '',\n",
    "        **params\n",
    "    )\n",
    "    pms[variation] = pm\n",
    "pm = list( pms.values() )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce6e87-f254-417a-9ace-01a3c5f5e79c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b356c5-80c2-40c8-b2ae-7cadf31283b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_fp = os.path.join( pm['polished_data_dir'], 'correlation_coefficients.h5' )\n",
    "correlations_all = verdict.Dict.from_hdf5( correlations_fp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f1a29-83b6-48cb-9732-8731c3533117",
   "metadata": {},
   "outputs": [],
   "source": [
    "absorption_properties_fp = os.path.join( pm['polished_data_dir'], 'absorption_system_properties.h5' )\n",
    "absorption_properties = verdict.Dict.from_hdf5( absorption_properties_fp, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016b1a2-fde5-406b-8aaa-e036eae29bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sls = list( correlations_all[pm['public_label']]['linear']['ndim'].keys() )\n",
    "n_sls = len( sls )\n",
    "xs = np.linspace( -0.5, 0.5, n_sls ) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d5c43-16cb-4bb8-b643-178224e327b4",
   "metadata": {},
   "source": [
    "# Distribution Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b387bb3-f596-4895-a711-5929223ac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_dist = [ [ 'vlos', 'T' ], [ 'nH', 'Z' ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b15524-f854-445b-a710-a10977c2f078",
   "metadata": {},
   "source": [
    "## Distributions themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a6b76-f29f-4a43-a203-abff5e4f6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dist_figs = []\n",
    "\n",
    "for i, sl in enumerate( sls ):\n",
    "\n",
    "    # Setup figure\n",
    "    fig = plt.figure()\n",
    "    main_ax = plt.gca()\n",
    "    main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "    for spine in main_ax.spines.values():\n",
    "        spine.set_visible( False )\n",
    "\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        mosaic_dist,\n",
    "    )\n",
    "\n",
    "    # main_ax.set_xlabel( '% of likelihood distribution enclosed', labelpad=30 )\n",
    "    # main_ax.set_ylabel( '% of synthetic data enclosed', labelpad=30 )\n",
    "\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "\n",
    "        ax.annotate(\n",
    "            text = helpers.property_labels_no_units[ax_key],\n",
    "            xy = ( 0, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( 5, -5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'left',\n",
    "        )\n",
    "\n",
    "        ax.set_xlim( helpers.lims[ax_key] )\n",
    "        ax.set_ylim( helpers.lims_1D[ax_key] )\n",
    "\n",
    "        ax.set_yscale( 'log' )\n",
    "        if helpers.logscale[ax_key]:\n",
    "            ax.set_xscale( 'log' )\n",
    "\n",
    "    main_ax.set_title(\n",
    "        label = sl,\n",
    "        loc = 'right',\n",
    "    )\n",
    "\n",
    "    for prop_key in ax_dict.keys():\n",
    "\n",
    "        # Get plot panel\n",
    "        ax = ax_dict[prop_key]\n",
    "        subplotspec = ax.get_subplotspec()\n",
    "\n",
    "        # Get data distributions\n",
    "        centers_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'][prop_key]\n",
    "        dist_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['distributions'][prop_key]\n",
    "\n",
    "        ax.fill_between(\n",
    "            centers_data,\n",
    "            dist_data,\n",
    "            color = 'k',\n",
    "            step = 'mid',\n",
    "        )\n",
    "\n",
    "        for variation, pm in pms.items():\n",
    "\n",
    "            # Modeled distribution\n",
    "            centers_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key]\n",
    "            bins_estimated = np.full( centers_estimated.shape, np.nan )\n",
    "            bin_widths = np.diff( centers_estimated )\n",
    "            bins_estimated[0:centers_estimated.size-1] = centers_estimated[:-1] - bin_widths / 2.\n",
    "            bins_estimated[centers_estimated.size-1] = centers_estimated[-1] + bin_widths[-1] / 2.\n",
    "            dist_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key]\n",
    "\n",
    "            ax.step(\n",
    "                centers_estimated,\n",
    "                dist_estimated,\n",
    "                where = 'mid',\n",
    "                color = helpers.colors_for_variations[variation],\n",
    "            )\n",
    "            \n",
    "    dist_figs.append( fig )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780aa8b2-4c6d-49a1-a7f9-0e54de3aa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_figs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c16d1-eec7-4812-8434-8465bde388f4",
   "metadata": {},
   "source": [
    "## Shape comparison\n",
    "Fraction enclosed compared to fraction enclosed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282a84a-bbdd-444f-a651-4954acdcc54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "f_estimated_to_enclose_f_data = verdict.Dict({})\n",
    "f_data_enclosed_by_f_estimated = verdict.Dict({})\n",
    "dist_comparison_figs = []\n",
    "for i, sl in enumerate( sls ):\n",
    "\n",
    "    # Setup figure\n",
    "    fig = plt.figure()\n",
    "    main_ax = plt.gca()\n",
    "    main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "    for spine in main_ax.spines.values():\n",
    "        spine.set_visible( False )\n",
    "\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        mosaic_dist,\n",
    "    )\n",
    "\n",
    "    main_ax.set_xlabel( '% of likelihood distribution enclosed', labelpad=30 )\n",
    "    main_ax.set_ylabel( '% of synthetic data enclosed', labelpad=30 )\n",
    "\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "        ax.set_xlim( 0, 100 )\n",
    "        ax.set_ylim( 0, 100 )\n",
    "\n",
    "        ax.annotate(\n",
    "            text = helpers.property_labels_no_units[ax_key],\n",
    "            xy = ( 0, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( 5, -5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'left',\n",
    "        )\n",
    "\n",
    "    main_ax.set_title(\n",
    "        label = sl,\n",
    "        loc = 'right',\n",
    "    )\n",
    "\n",
    "    for variation, pm in pms.items():\n",
    "\n",
    "        for prop_key in absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'].keys():\n",
    "\n",
    "            # Get plot panel\n",
    "            ax = ax_dict[prop_key]\n",
    "            subplotspec = ax.get_subplotspec()\n",
    "\n",
    "            # Get data distributions\n",
    "            centers_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'][prop_key]\n",
    "            dist_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['distributions'][prop_key]\n",
    "            dist_data_sum = dist_data.sum()\n",
    "\n",
    "            # Get modeled distributions\n",
    "            centers_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key]\n",
    "            bins_estimated = np.full( centers_estimated.shape, np.nan )\n",
    "            bin_widths = np.diff( centers_estimated )\n",
    "            bins_estimated[0:centers_estimated.size-1] = centers_estimated[:-1] - bin_widths / 2.\n",
    "            bins_estimated[centers_estimated.size-1] = centers_estimated[-1] + bin_widths[-1] / 2.\n",
    "            dist_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key]\n",
    "            dist_estimated_sum = dist_estimated.sum()\n",
    "            max_ind_estimated = dist_estimated.argmax()\n",
    "\n",
    "            # Calculate fraction included arrays\n",
    "            j = 0\n",
    "            f_included_data = []\n",
    "            f_included_estimated = []\n",
    "            while True:\n",
    "\n",
    "                # Get range to include\n",
    "                left = max_ind_estimated - j\n",
    "                right = max_ind_estimated + j + 1\n",
    "\n",
    "                # Check if looping is done\n",
    "                left_in_bounds = left >= 0\n",
    "                right_in_bounds = right < centers_estimated.size\n",
    "                continue_looping = left_in_bounds or right_in_bounds\n",
    "                if not continue_looping:\n",
    "                    break\n",
    "                    \n",
    "                if not left_in_bounds:\n",
    "                    left = 0\n",
    "                if not right_in_bounds:\n",
    "                    right = centers_estimated.size - 1\n",
    "\n",
    "                # Get fraction included\n",
    "                x_value_left = bins_estimated[left]\n",
    "                x_value_right = bins_estimated[right]\n",
    "                is_in_range_data = ( centers_data > x_value_left ) & (centers_data < x_value_right )\n",
    "\n",
    "                f_included_data.append( dist_data[is_in_range_data].sum() / dist_data_sum )\n",
    "                f_included_estimated.append( dist_estimated[left:right].sum() / dist_estimated_sum )\n",
    "\n",
    "                j += 1\n",
    "            f_included_data = np.array( f_included_data )\n",
    "            f_included_estimated = np.array( f_included_estimated )\n",
    "            \n",
    "            # Extract a summary statistic\n",
    "            interp_data_estimated = scipy.interpolate.interp1d( f_included_data, f_included_estimated )\n",
    "            interp_estimated_data = scipy.interpolate.interp1d( f_included_estimated, f_included_data )\n",
    "            for fraction in pm['f_enclosed']:\n",
    "                \n",
    "                ## Fraction needed to enclose\n",
    "                try:\n",
    "                    f_to_enclose = interp_data_estimated( fraction )\n",
    "                    \n",
    "                    # If a value of 1 is needed, then the distribution doesn't actually enclose the data.\n",
    "                    if np.isclose( f_to_enclose, 1. ):\n",
    "                        f_to_enclose = np.nan\n",
    "                # If above or below the interpolation range\n",
    "                except ValueError:\n",
    "                    # If below, that means the fraction was reached with the first cell\n",
    "                    if fraction <= f_included_data[0]:\n",
    "                        f_to_enclose = f_included_estimated[0]\n",
    "                    # If above, then invalid\n",
    "                    elif fraction >= f_included_data[-1]:\n",
    "                        f_to_enclose = np.nan\n",
    "                f_estimated_to_enclose_f_data.setitem( pm['public_label'], f_to_enclose, prop_key, str( fraction ), sl )\n",
    "                \n",
    "                ## Fraction enclosed by a fixed value\n",
    "                try:\n",
    "                    f_data_enclosed = interp_estimated_data( fraction )\n",
    "                # If above or below the interpolation range\n",
    "                except ValueError:\n",
    "                    # If below the interpolation range, then f_estimated jumps sharply early, so the enclosed amount is just the first entry in f_included_data\n",
    "                    if fraction < f_included_estimated[0]:\n",
    "                        f_data_enclosed = f_included_data[0]\n",
    "                    # If above the interpolation range, then invalid\n",
    "                    if fraction >= f_included_estimated[-1]:\n",
    "                        f_data_enclosed = np.nan\n",
    "                f_data_enclosed_by_f_estimated.setitem( pm['public_label'], f_data_enclosed, prop_key, str( fraction ), sl )\n",
    "\n",
    "            ax.plot(\n",
    "                f_included_estimated * 100,\n",
    "                f_included_data * 100,\n",
    "                color = helpers.colors_for_variations[pm['variation']],\n",
    "            )\n",
    "            \n",
    "    dist_comparison_figs.append( fig )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087b92c-644b-445e-9e2f-5c494763930f",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30080e62-61da-44b7-b857-5aa6901b919e",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdca93e-9ed4-4070-8735-705eea90e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = verdict.Dict({})\n",
    "distances_between = verdict.Dict({})\n",
    "percentiles = verdict.Dict({})\n",
    "for i, sl in enumerate( sls ):\n",
    "\n",
    "    for prop_key in absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'].keys():\n",
    "\n",
    "        # Get plot panel\n",
    "        ax = ax_dict[prop_key]\n",
    "        subplotspec = ax.get_subplotspec()\n",
    "\n",
    "        # Get data distributions\n",
    "        centers_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'][prop_key]\n",
    "        if helpers.logscale[prop_key]:\n",
    "            centers_data = np.log10( centers_data )\n",
    "        dist_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['distributions'][prop_key]\n",
    "        dist_data_sum = dist_data.sum()\n",
    "        cdf_data = np.cumsum( dist_data ) / dist_data_sum\n",
    "        interp_data = scipy.interpolate.interp1d( cdf_data, centers_data )\n",
    "        \n",
    "        # Calculate data average\n",
    "        avg_data = interp_data( 0.5 )\n",
    "        averages.setitem( 'source', avg_data, prop_key, sl )\n",
    "\n",
    "        for fraction in pm['f_enclosed']:\n",
    "            \n",
    "            # Calculate data percentiles\n",
    "            interval_data = np.array([ interp_data( fraction / 2. ), interp_data( 1. - fraction / 2. ) ])\n",
    "            width_data = interval_data[1] - interval_data[0]\n",
    "            percentiles.setitem( 'source', interval_data, prop_key, str( fraction ), 'interval', sl )\n",
    "            percentiles.setitem( 'source', width_data, prop_key, str( fraction ), 'width', sl )\n",
    "            \n",
    "            for variation, pm in pms.items():\n",
    "\n",
    "                # Get modeled distributions\n",
    "                centers_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key]\n",
    "                if helpers.logscale[prop_key]:\n",
    "                    centers_estimated = np.log10( centers_estimated )\n",
    "                dist_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key]\n",
    "                dist_estimated_sum = dist_estimated.sum()\n",
    "                cdf_estimated = np.cumsum( dist_estimated ) / dist_estimated_sum\n",
    "                interp_estimated = scipy.interpolate.interp1d( cdf_estimated, centers_estimated )\n",
    "                \n",
    "                # Calculate MLE and averages\n",
    "                x_max = centers_estimated[np.argmax( dist_estimated )]\n",
    "                x_avg = interp_estimated( 0.5 )\n",
    "                averages.setitem( 'parameter_estimation', x_max, pm['public_label'], 'MLE', prop_key, sl )\n",
    "                averages.setitem( 'parameter_estimation', x_avg, pm['public_label'], 'average', prop_key, sl )\n",
    "\n",
    "                # Calculate parameter estimation percentiles\n",
    "                interval = np.array([ interp_estimated( fraction / 2. ), interp_estimated( 1. - fraction / 2. ) ])\n",
    "                width = interval[1] - interval[0]\n",
    "                percentiles.setitem( 'parameter_estimation', interval, pm['public_label'], prop_key, str( fraction ), 'interval', sl )\n",
    "                percentiles.setitem( 'parameter_estimation', width, pm['public_label'], prop_key, str( fraction ), 'width', sl )\n",
    "\n",
    "                # Calculate necessary width\n",
    "                width_necessary = np.max( np.abs( interval_data - x_max ) )\n",
    "                width_between_peaks = np.abs( avg_data - x_max )\n",
    "                distances_between.setitem( pm['public_label'], width_necessary, prop_key, 'distance_to_enclose', str( fraction ), sl )\n",
    "                distances_between.setitem( pm['public_label'], width_between_peaks, prop_key, 'distance_to_avg', sl )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331e51b-cd38-4afc-8d23-d7d0656763cc",
   "metadata": {},
   "source": [
    "## Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0142080-2bec-49b0-8e7a-54b1fb6b266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric( get_ys ):\n",
    "    \n",
    "    # Setup figure\n",
    "    n_rows = len( mosaic_dist )\n",
    "    n_cols = 3.5\n",
    "    fig = plt.figure( figsize=(n_cols*panel_length, n_rows*panel_length), facecolor='w' )\n",
    "    main_ax = plt.gca()\n",
    "    main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "    for spine in main_ax.spines.values():\n",
    "        spine.set_visible( False )\n",
    "\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        mosaic_dist,\n",
    "    )\n",
    "    \n",
    "    # Axes tweaks\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "\n",
    "        ax.set_xticks( xs )\n",
    "        xtick_labels = [ _[-2:] for _ in sls ]\n",
    "        ax.set_xticklabels( xtick_labels )\n",
    "\n",
    "        ax.annotate(\n",
    "            text = helpers.property_labels_no_units[ax_key],\n",
    "            xy = ( 0, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( 5, -5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'left',\n",
    "        )\n",
    "        \n",
    "\n",
    "    for variation, pm in pms.items():\n",
    "\n",
    "        for ax_key, ax in ax_dict.items():\n",
    "        \n",
    "            ys = get_ys( variation=variation, prop_key=ax_key )\n",
    "\n",
    "            color = helpers.colors_for_variations[pm['variation']]\n",
    "            fill_color = color\n",
    "            scatter = ax.scatter(\n",
    "                xs,\n",
    "                ys,\n",
    "                s = 100,\n",
    "                edgecolor = color,\n",
    "                color = fill_color,\n",
    "            )\n",
    "    \n",
    "    return fig, main_ax, ax_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c3b61-2730-4c46-b3d0-0b83bad3c4cc",
   "metadata": {},
   "source": [
    "## MLEs and Average Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb76e1c-cfbb-4f88-bd02-501f45a4d1fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Straight up MLEs and averages    \n",
    "def get_ys( variation, prop_key ):\n",
    "\n",
    "    pm = pms[variation]\n",
    "\n",
    "    x_mle = averages['parameter_estimation'][pm['public_label']]['MLE'][prop_key].array()\n",
    "    return x_mle\n",
    "\n",
    "fig, main_ax, ax_dict = plot_metric( get_ys )\n",
    "\n",
    "main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "main_ax.set_ylabel( r'$x_{\\rm MLE}$', labelpad=30 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544bff7-3e98-4669-b88c-6b77e8b07527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fraction in pm['f_enclosed']:\n",
    "    \n",
    "    def get_ys( variation, prop_key ):\n",
    "        \n",
    "        pm = pms[variation]\n",
    "        \n",
    "        d_between = distances_between[pm['public_label']][prop_key]['distance_to_avg'].array()\n",
    "        return d_between\n",
    "    \n",
    "    fig, main_ax, ax_dict = plot_metric( get_ys )\n",
    "\n",
    "    main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "    main_ax.set_ylabel( r'$\\left| x_{\\rm MLE} - \\langle x \\rangle \\right|$', labelpad=30 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc4218-1a28-4fb2-9e5c-9767e83f60fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Distribution Widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f371a-f251-418c-958f-5f4fe6c418c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fraction in pm['f_enclosed']:\n",
    "    \n",
    "    def get_widths( variation, prop_key ):\n",
    "        \n",
    "        pm = pms[variation]\n",
    "        \n",
    "        percentile = percentiles['parameter_estimation'][pm['public_label']][prop_key][str(fraction)]['width'].array()\n",
    "        d_between = distances_between[pm['public_label']][prop_key]['distance_to_avg'].array()\n",
    "        return percentile / d_between\n",
    "    \n",
    "    fig, main_ax, ax_dict = plot_metric( get_widths )\n",
    "\n",
    "    main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "    main_ax.set_ylabel( '{}'.format( int( fraction * 100 ) ) + r'th percentile / $\\left| x_{\\rm MLE} - \\langle x \\rangle \\right|$', labelpad=30 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f7b75-4ce9-4189-b8ca-58050a01a738",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fraction enclosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693aee52-c696-4962-a2bc-eb38cda69a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for fraction in pm['f_enclosed']:\n",
    "\n",
    "    # Setup figure\n",
    "    n_rows_clean = 2\n",
    "    n_cols_clean = 3.5\n",
    "    fig = plt.figure( figsize=(n_cols_clean*panel_length, n_rows_clean*panel_length), facecolor='w' )\n",
    "    main_ax = plt.gca()\n",
    "    main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "    for spine in main_ax.spines.values():\n",
    "        spine.set_visible( False )\n",
    "\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        dist_mosaic,\n",
    "    )\n",
    "\n",
    "    main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "    main_ax.set_ylabel( '% of likelihood that encloses {}% of the data'.format( int( fraction * 100 ) ), labelpad=30 )\n",
    "\n",
    "    # Axes tweaks\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "        ax.set_ylim( 0, 100 )\n",
    "\n",
    "        ax.set_xticks( xs )\n",
    "        xtick_labels = [ _[-2:] for _ in list( f_estimated_to_enclose_f_data[pm['public_label']][ax_key][str(fraction)].keys() ) ]\n",
    "        ax.set_xticklabels( xtick_labels )\n",
    "\n",
    "        ax.annotate(\n",
    "            text = helpers.property_labels_no_units[ax_key],\n",
    "            xy = ( 0, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( 5, -5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'left',\n",
    "        )\n",
    "        \n",
    "        ax.axhline(\n",
    "            fraction * 100,\n",
    "            color = '0.5',\n",
    "        )\n",
    "\n",
    "    for variation, pm in pms.items():\n",
    "\n",
    "        for ax_key, ax in ax_dict.items():\n",
    "\n",
    "            ys = f_estimated_to_enclose_f_data[pm['public_label']][ax_key][str(fraction)].array() * 100\n",
    "\n",
    "            color = helpers.colors_for_variations[pm['variation']]\n",
    "            fill_color = color\n",
    "            scatter = ax.scatter(\n",
    "                xs,\n",
    "                ys,\n",
    "                s = 100,\n",
    "                edgecolor = color,\n",
    "                color = fill_color,\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6ed54-3a56-4940-8d74-65036724f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for fraction in pm['f_enclosed']:\n",
    "\n",
    "    # Setup figure\n",
    "    n_rows_clean = 2\n",
    "    n_cols_clean = 3.5\n",
    "    fig = plt.figure( figsize=(n_cols_clean*panel_length, n_rows_clean*panel_length), facecolor='w' )\n",
    "    main_ax = plt.gca()\n",
    "    main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "    for spine in main_ax.spines.values():\n",
    "        spine.set_visible( False )\n",
    "\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        dist_mosaic,\n",
    "    )\n",
    "\n",
    "    main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "    main_ax.set_ylabel( '% of data enclosed by {}% of the likelihood'.format( int( fraction * 100 ) ), labelpad=30 )\n",
    "\n",
    "    # Axes tweaks\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "        ax.set_ylim( 0, 100 )\n",
    "\n",
    "        ax.set_xticks( xs )\n",
    "        xtick_labels = [ _[-2:] for _ in list( f_data_enclosed_by_f_estimated[pm['public_label']][ax_key][str(fraction)].keys() ) ]\n",
    "        ax.set_xticklabels( xtick_labels )\n",
    "\n",
    "        ax.annotate(\n",
    "            text = helpers.property_labels_no_units[ax_key],\n",
    "            xy = ( 0, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( 5, -5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'left',\n",
    "        )\n",
    "        \n",
    "        ax.axhline(\n",
    "            fraction * 100,\n",
    "            color = '0.5',\n",
    "        )\n",
    "\n",
    "    for variation, pm in pms.items():\n",
    "\n",
    "        for ax_key, ax in ax_dict.items():\n",
    "\n",
    "            ys = f_data_enclosed_by_f_estimated[pm['public_label']][ax_key][str(fraction)].array() * 100\n",
    "\n",
    "            color = helpers.colors_for_variations[pm['variation']]\n",
    "            fill_color = color\n",
    "            scatter = ax.scatter(\n",
    "                xs,\n",
    "                ys,\n",
    "                s = 100,\n",
    "                edgecolor = color,\n",
    "                color = fill_color,\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970c7c2-60fc-4868-bdee-1d4bf2048b2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd0677-d7ea-43bd-996a-2f71812a5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mosaic = [\n",
    "    # [ 'all', 'all', 'all', 'legend' ],\n",
    "    [ 'vlos', 'vlos', 'T', 'T', ],\n",
    "    [ 'nH', 'nH', 'Z', 'Z', ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50461f2f-f186-452a-8a09-302cc6062d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Figure\n",
    "n_rows_clean = len( clean_mosaic )\n",
    "n_cols_clean = 3.5\n",
    "fig = plt.figure( figsize=(n_cols_clean*panel_length, n_rows_clean*panel_length), facecolor='w' )\n",
    "ax_dict = fig.subplot_mosaic(\n",
    "    clean_mosaic,\n",
    "    gridspec_kw = { 'wspace': 0.7 },\n",
    ")\n",
    "ax_dict['legend'] = ax_dict['vlos']\n",
    "\n",
    "def r_scatter( ax, ys, c_key, color=None, label_tag=None ):\n",
    "    c_params = correlation_coefficients[c_key]\n",
    "    if 'logscale' in c_params:\n",
    "        if c_params['logscale']:\n",
    "            facecolors = 'none'\n",
    "    else:\n",
    "        facecolors = color\n",
    "        \n",
    "    scatter = ax.scatter(\n",
    "        xs,\n",
    "        ys,\n",
    "        label = '{}, {}'.format( label_tag, c_key ),\n",
    "        edgecolors = color,\n",
    "        facecolors = facecolors,\n",
    "        marker = correlation_markers[c_key],\n",
    "        s = correlation_sizes[c_key],\n",
    "        linewidth = 2,\n",
    "    )\n",
    "\n",
    "    \n",
    "# Overall\n",
    "for variation, pm in pms.items():\n",
    "    \n",
    "    correlations = correlations_all[pm['public_label']]\n",
    "    plotting_params = variation_plotting_params[variation]\n",
    "    \n",
    "    # for c_key in correlations_plotted:\n",
    "    #     r_scatter(\n",
    "    #         ax_dict['all'],\n",
    "    #         correlations[c_key]['ndim'].array(),\n",
    "    #         c_key,\n",
    "    #         color = plotting_params['color'],\n",
    "    #     )\n",
    "\n",
    "    # Each property\n",
    "    for j, x_key in enumerate( tqdm.tqdm( pm['prop_keys'], bar_format=pm['bar_format'] ) ):\n",
    "\n",
    "        ax = ax_dict[x_key]\n",
    "\n",
    "        for c_key in correlations_plotted:\n",
    "            r_scatter(\n",
    "                ax,\n",
    "                correlations[c_key]['matrix'].array()[:,j,j],\n",
    "                c_key,\n",
    "                color = plotting_params['color'],\n",
    "                label_tag = plotting_params['label'],\n",
    "            )\n",
    "    \n",
    "        \n",
    "# Add a legend\n",
    "h, l = ax_dict['vlos'].get_legend_handles_labels()\n",
    "legend = ax_dict['legend'].legend(\n",
    "    h,\n",
    "    l,\n",
    "    loc = 'lower left',\n",
    "    prop = {'size': 14},\n",
    "    ncol = 2,\n",
    "    framealpha = 1,\n",
    ")\n",
    "# ax_dict['legend'].axis( 'off' )\n",
    "# ax_dict['legend'].annotate(\n",
    "#     text = r'$r = \\frac{ \\langle {\\rm actual } \\vert  {\\rm found } \\rangle }{ \\vert {\\rm actual} \\vert \\vert {\\rm found } \\vert }$',\n",
    "#     xy = ( 0, 1 ),\n",
    "#     xycoords = 'axes fraction',\n",
    "#     xytext = ( 5, -5 ),\n",
    "#     textcoords = 'offset points',\n",
    "#     ha = 'center',\n",
    "#     va = 'top',\n",
    "#     fontsize = 18,\n",
    "# )\n",
    "        \n",
    "# Cleanup\n",
    "for x_key, ax in ax_dict.items():\n",
    "    \n",
    "    if x_key in [ 'legend', 'empty' ]:\n",
    "        continue\n",
    "    \n",
    "    subplotspec = ax.get_subplotspec()\n",
    "    \n",
    "    for value in [ -1, 0, 1 ]:\n",
    "        ax.axhline(\n",
    "            value,\n",
    "            color = pm['background_linecolor'],\n",
    "            linewidth = 1,\n",
    "            zorder = -100,\n",
    "        )\n",
    "        \n",
    "    ax.set_ylabel( r_labels[x_key], fontsize=16 )\n",
    "    if subplotspec.is_last_row():\n",
    "        ax.set_xlabel( 'sightline ID', fontsize=16 )\n",
    "        \n",
    "    ax.set_xticks( xs )\n",
    "    xtick_labels = [ _[-2:] for _ in correlations[c_key]['ndim'].keys_array() ]\n",
    "    ax.set_xticklabels( xtick_labels )\n",
    "        \n",
    "    ax.set_ylim( -0.3, 1.1 )\n",
    "    \n",
    "# Save\n",
    "savedir = pm['figure_dir']\n",
    "os.makedirs( savedir, exist_ok=True )\n",
    "savefile = 'correlations.pdf'\n",
    "save_fp = os.path.join( savedir, savefile )\n",
    "print( 'Saving figure to {}'.format( save_fp ) )\n",
    "plt.savefig( save_fp, bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c332c3-cdcf-4932-a3d8-2b6ce27c0949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754b996-3aeb-4c42-8cc8-a7badc8c03bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
