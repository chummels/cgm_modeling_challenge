{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc1b6d-4adb-4157-87a3-03622632e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fed0f2-7d47-4955-ac25-640d09f77aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import trident\n",
    "import unyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc0084-d12d-45ad-a209-d9078dd8f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kalepy as kale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f22441-2234-40ec-baae-ebe1edd862e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trove\n",
    "import verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1af51-24eb-47a0-aadf-175ecdcbd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Currently need to call this to get matplotlib selected style to load...\n",
    "plt.plot()\n",
    "matplotlib.style.use( '/Users/zhafen/repos/clean-bold/clean-bold.mplstyle' )\n",
    "import palettable\n",
    "import matplotlib.patheffects as path_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb0fd2-1b28-4f48-ba5b-c8a24a134c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f085e-92e7-4860-a9a8-7c038bef9947",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb637a3-81dd-4abb-a1ed-a13f18c8fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "variations = [ \n",
    "    'original',\n",
    "    'high-z',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede9ac4-52f5-4e59-9eeb-b720128fc41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Analysis \n",
    "    'prop_keys': [ 'vlos', 'T', 'nH', 'Z' ],\n",
    "    'vel_prop_keys': [ 'vlos', 'T', 'nH', 'Z', 'NHI' ],\n",
    "    'broaden_models': True,\n",
    "    '1D_dist_estimation': 'kde',\n",
    "    '1D_dist_estimation_data': 'histogram',\n",
    "    '2D_dist_estimation': 'histogram',\n",
    "    'export_data_for_proposal': False,\n",
    "    'f_enclosed': [ 0.5, 0.75, 0.9, 0.99 ],\n",
    "    \n",
    "    # Plotting Choices\n",
    "    'smooth_2D_dist': 0.5,\n",
    "    'upsample_2D_dist': 3,\n",
    "    '2D_dist_data_display': 'histogram',\n",
    "    'contour_levels': [ 90, 50 ],\n",
    "    'contour_linewidths': [ 1, 3 ],\n",
    "    'show_plots_in_nb': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f4aca5-0604-4f41-bf5f-4ec87fe98db7",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d5523-475b-4166-a97a-368fd2e4593c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ecdfad-1324-4c0a-aa85-14c0827e7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_plotting_params = {\n",
    "    'original': {\n",
    "        'color': helpers.blinded_color,\n",
    "        'label': 'estimated',\n",
    "        'offset': -0.2,\n",
    "    },\n",
    "    'high-z': {\n",
    "        'color': helpers.revised_color,\n",
    "        'label': 'revised',\n",
    "        'offset': 0.2,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd7e37-7f32-46c9-8313-73d64f78ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_markers = {\n",
    "    'one-sided': '^',\n",
    "    'log one-sided': '^',\n",
    "    'two-sided': 'D',\n",
    "    'linear': 'o',\n",
    "    'log': 'o',\n",
    "}\n",
    "correlation_sizes = {\n",
    "    'one-sided': 100,\n",
    "    'log one-sided': 100,\n",
    "    'two-sided': 80,\n",
    "    'linear': 100,\n",
    "    'log': 100,\n",
    "}\n",
    "correlations_plotted = [ 'linear', 'log' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e4170d-07c9-442f-902b-a3fe0de1c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = [\n",
    "    [ 'vlos', 'legend', '.', '.' ],\n",
    "    [ 'T_vlos', 'T', '.', '.' ],\n",
    "    [ 'nH_vlos', 'nH_T', 'nH', '.' ],\n",
    "    [ 'Z_vlos', 'Z_T', 'Z_nH', 'Z', ],\n",
    "]\n",
    "velocity_mosaic = [\n",
    "    [ 'nH_vlos', 'vlos', ],\n",
    "    [ 'Z_vlos', 'T_vlos', ],\n",
    "]\n",
    "mosaic_dist = [ [ 'vlos', 'Z' ], [ 'T', 'nH' ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7c229-5fe0-40cb-8760-bc52354aa57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = palettable.cartocolors.qualitative.Safe_10.mpl_colors\n",
    "corr_cmap = palettable.cartocolors.diverging.Temps_2_r.mpl_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85890ae-1d72-4668-82e1-ca6459cf8967",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_norm = matplotlib.colors.Normalize( vmin=0, vmax=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3186f-3044-4a63-ada9-0288422c3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_color_linear_cmap( color, name, f_white=0.95, f_saturated=1.0, ):\n",
    "    '''A function that turns a single color into linear colormap that\n",
    "    goes from a color that is whiter than the original color to a color\n",
    "    that is more saturated than the original color.\n",
    "    '''\n",
    "    \n",
    "    color_hsv = matplotlib.colors.rgb_to_hsv( color )\n",
    "    start_color_hsv = copy.copy( color_hsv )\n",
    "    \n",
    "    start_color_hsv = copy.copy( color_hsv )\n",
    "    start_color_hsv[1] -= f_white * start_color_hsv[1]\n",
    "    start_color_hsv[2] += f_white * ( 1. - start_color_hsv[2] )\n",
    "    start_color = matplotlib.colors.hsv_to_rgb( start_color_hsv )\n",
    "    \n",
    "    end_color_hsv = copy.copy( color_hsv )\n",
    "    end_color_hsv[1] += f_saturated * ( 1. - end_color_hsv[1] )\n",
    "    end_color = matplotlib.colors.hsv_to_rgb( end_color_hsv )\n",
    "    \n",
    "    return matplotlib.colors.LinearSegmentedColormap.from_list( name, [ start_color, end_color ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e4210-7fdf-4d0e-b3fb-2c4771a3f153",
   "metadata": {},
   "source": [
    "## Process analysis parameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b938d2a-72bf-4f17-8534-3379712e2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "pms = {}\n",
    "for variation in variations:\n",
    "    pm = trove.link_params_to_config(\n",
    "        '/Users/zhafen/analysis/cgm_modeling_challenge/sample2.trove',\n",
    "        script_id = 'nb.2',\n",
    "        variation = variation,\n",
    "        global_variation = '',\n",
    "        **params\n",
    "    )\n",
    "    pms[variation] = pm\n",
    "pm = list( pms.values() )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce6e87-f254-417a-9ace-01a3c5f5e79c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b356c5-80c2-40c8-b2ae-7cadf31283b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_fp = os.path.join( pm['polished_data_dir'], 'correlation_coefficients.h5' )\n",
    "correlations_all = verdict.Dict.from_hdf5( correlations_fp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f1a29-83b6-48cb-9732-8731c3533117",
   "metadata": {},
   "outputs": [],
   "source": [
    "absorption_properties_fp = os.path.join( pm['polished_data_dir'], 'absorption_system_properties.h5' )\n",
    "absorption_properties = verdict.Dict.from_hdf5( absorption_properties_fp, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016b1a2-fde5-406b-8aaa-e036eae29bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sls = list( correlations_all[pm['public_label']]['linear']['ndim'].keys() )\n",
    "n_sls = len( sls )\n",
    "xs = np.linspace( -0.5, 0.5, n_sls ) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d5c43-16cb-4bb8-b643-178224e327b4",
   "metadata": {},
   "source": [
    "# Distribution Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b15524-f854-445b-a710-a10977c2f078",
   "metadata": {},
   "source": [
    "## 1D Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a6b76-f29f-4a43-a203-abff5e4f6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dist_figs = []\n",
    "\n",
    "for i, sl in enumerate( sls ):\n",
    "\n",
    "    # Setup figure\n",
    "    fig = plt.figure()\n",
    "    main_ax = plt.gca()\n",
    "    main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "    for spine in main_ax.spines.values():\n",
    "        spine.set_visible( False )\n",
    "\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        mosaic_dist,\n",
    "    )\n",
    "\n",
    "    # main_ax.set_xlabel( '% of likelihood distribution enclosed', labelpad=30 )\n",
    "    # main_ax.set_ylabel( '% of synthetic data enclosed', labelpad=30 )\n",
    "\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "\n",
    "        ax.annotate(\n",
    "            text = helpers.property_labels_no_units[ax_key],\n",
    "            xy = ( 0, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( 5, -5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'left',\n",
    "        )\n",
    "\n",
    "        ax.set_xlim( helpers.lims[ax_key] )\n",
    "        ax.set_ylim( helpers.lims_1D[ax_key] )\n",
    "\n",
    "        ax.set_yscale( 'log' )\n",
    "        if helpers.logscale[ax_key]:\n",
    "            ax.set_xscale( 'log' )\n",
    "\n",
    "    main_ax.set_title(\n",
    "        label = sl,\n",
    "        loc = 'right',\n",
    "    )\n",
    "\n",
    "    for prop_key in ax_dict.keys():\n",
    "\n",
    "        # Get plot panel\n",
    "        ax = ax_dict[prop_key]\n",
    "        subplotspec = ax.get_subplotspec()\n",
    "\n",
    "        # Get data distributions\n",
    "        centers_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'][prop_key]\n",
    "        dist_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['distributions'][prop_key]\n",
    "\n",
    "        ax.fill_between(\n",
    "            centers_data,\n",
    "            dist_data,\n",
    "            color = 'k',\n",
    "            step = 'mid',\n",
    "        )\n",
    "\n",
    "        for variation, pm in pms.items():\n",
    "\n",
    "            # Modeled distribution\n",
    "            centers_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key]\n",
    "            bins_estimated = np.full( centers_estimated.shape, np.nan )\n",
    "            bin_widths = np.diff( centers_estimated )\n",
    "            bins_estimated[0:centers_estimated.size-1] = centers_estimated[:-1] - bin_widths / 2.\n",
    "            bins_estimated[centers_estimated.size-1] = centers_estimated[-1] + bin_widths[-1] / 2.\n",
    "            dist_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key]\n",
    "\n",
    "            ax.step(\n",
    "                centers_estimated,\n",
    "                dist_estimated,\n",
    "                where = 'mid',\n",
    "                color = helpers.colors_for_variations[variation],\n",
    "            )\n",
    "            \n",
    "    dist_figs.append( fig )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780aa8b2-4c6d-49a1-a7f9-0e54de3aa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_figs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f71b4f-4663-4ddd-82d6-67285df6e678",
   "metadata": {},
   "source": [
    "## Violin Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b963a-9dca-43d1-903d-1b0ed9a46c30",
   "metadata": {},
   "source": [
    "### Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956cdab-b117-40f9-8d06-451753b387b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload( helpers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ec109-6a1f-4c4a-9ba5-e5018b491124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin( get_violin_input, pms, fig_tuple=None, color='k', use_helper_colors=True, alpha=0.5, logscale_distributions=False ):\n",
    "\n",
    "    if fig_tuple is None:\n",
    "        n_rows = len( mosaic_dist )\n",
    "        n_cols = len( mosaic_dist[0] )\n",
    "        fig = plt.figure( figsize=(n_cols*helpers.figure_width, n_rows*helpers.figure_height), facecolor='w' )\n",
    "        main_ax = plt.gca()\n",
    "        main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "        for spine in main_ax.spines.values():\n",
    "            spine.set_visible( False )\n",
    "\n",
    "        ax_dict = fig.subplot_mosaic(\n",
    "            mosaic_dist,\n",
    "            gridspec_kw = { 'hspace': 0.15, 'wspace': 0.12 },\n",
    "        )\n",
    "    else:\n",
    "        fig, main_ax, ax_dict = fig_tuple\n",
    "        \n",
    "    # Axes tweaks\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "\n",
    "        ylim = helpers.lims[ax_key]\n",
    "\n",
    "        # Logscale handling\n",
    "        axis_label = helpers.property_labels_no_units[ax_key]\n",
    "        if helpers.logscale[ax_key]:\n",
    "            axis_label = 'log' + axis_label\n",
    "            ylim = np.log10( ylim )\n",
    "\n",
    "        ax.set_ylim( ylim )\n",
    "        ax.set_xticks( xs )\n",
    "        xtick_labels = [ _[-2:] for _ in sls ]\n",
    "        ax.set_xticklabels( xtick_labels )\n",
    "                \n",
    "        ax.set_ylabel( helpers.property_labels[ax_key] )\n",
    "        \n",
    "        if ax.get_subplotspec().is_last_row():\n",
    "            ax.set_xlabel( 'sightline ID', )\n",
    "        \n",
    "    for variation, pm in pms.items():\n",
    "\n",
    "        for ax_key, ax in ax_dict.items():\n",
    "\n",
    "            values = []\n",
    "            invalid_in_list = False\n",
    "            for sl in sls:\n",
    "                \n",
    "                centers, dist = get_violin_input( variation, sl, ax_key )\n",
    "                \n",
    "                if centers is None:\n",
    "                    invalid_in_list = True\n",
    "                    break\n",
    "\n",
    "                if helpers.logscale[ax_key]:\n",
    "                    centers = np.log10( centers )\n",
    "\n",
    "                # Convert distribution to logscale\n",
    "                if logscale_distributions:\n",
    "                    dist_min = dist[dist > 0].min()\n",
    "                    dist[dist<dist_min] = dist_min\n",
    "                    dist = np.log10( dist )\n",
    "                    dist -= np.log10( dist_min )\n",
    "\n",
    "                # Resample\n",
    "                kde = kale.KDE.from_hist(\n",
    "                    centers,\n",
    "                    dist[:-1],\n",
    "                )\n",
    "                values.append( kde.resample( 1000 ) )\n",
    "                \n",
    "            if invalid_in_list:\n",
    "                continue\n",
    "                \n",
    "            if use_helper_colors:\n",
    "                color = helpers.colors_for_variations[pm['variation']]\n",
    "\n",
    "            v = ax.violinplot(\n",
    "                values,\n",
    "                xs,\n",
    "                widths = np.diff( xs )[0] * helpers.violin_width,\n",
    "                showextrema = False\n",
    "            )\n",
    "            for i, poly in enumerate( v['bodies'] ):\n",
    "                poly.set_alpha( alpha )\n",
    "                poly.set_color( color )\n",
    "                \n",
    "    return fig, main_ax, ax_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a691bc8a-8f95-46a8-a3f1-66dc72b16196",
   "metadata": {},
   "source": [
    "### Source Violin, Other Source Violin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c7a0b-ee84-4263-8811-a5289ffa6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source( variation, sl, prop_key ):\n",
    "    \n",
    "    pm = pms[variation]\n",
    "    \n",
    "    centers = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['centers'][prop_key] )\n",
    "    dist = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['distributions'][prop_key] )\n",
    "    \n",
    "    return centers, dist\n",
    "\n",
    "fig, main_ax, ax_dict = plot_violin( get_source, pms, color='k', use_helper_colors=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4774d275-edad-4f6a-8d03-32e6b8fb4b75",
   "metadata": {},
   "source": [
    "As expected, no significant differences between the source distribution between revisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150aed5-55e9-4395-a992-4aba7a790268",
   "metadata": {},
   "source": [
    "### Separated ( Source Violins, Estimated Violins )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6fc997-bfcf-46e4-bc6a-572cd0d5624f",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b4b30-6c2d-4b4f-872b-c44c667c6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variation, pm in pms.items():\n",
    "\n",
    "    def get_source( variation, sl, prop_key ):\n",
    "\n",
    "        pm = pms[variation]\n",
    "\n",
    "        centers = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['centers'][prop_key] )\n",
    "        dist = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['distributions'][prop_key] )\n",
    "\n",
    "        return centers, dist\n",
    "\n",
    "    def get_estimate( variation, sl, prop_key ):\n",
    "\n",
    "        centers = copy.copy( absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key] )\n",
    "        dist = copy.copy( absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key] )\n",
    "\n",
    "        return centers, dist\n",
    "\n",
    "    fig_tuple = plot_violin( get_source, { variation: pm }, color='k', use_helper_colors=False, alpha=1 )\n",
    "\n",
    "    fig_tuple = plot_violin( get_estimate, { variation: pm }, fig_tuple=fig_tuple )\n",
    "    \n",
    "    fig_tuple[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2986da-2e29-4289-9ef9-42ba19fde640",
   "metadata": {},
   "source": [
    "#### Logscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b6014-b878-4981-8b1e-1e3b84a5b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variation, pm in pms.items():\n",
    "\n",
    "    def get_source( variation, sl, prop_key ):\n",
    "\n",
    "        pm = pms[variation]\n",
    "\n",
    "        centers = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['centers'][prop_key] )\n",
    "        dist = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['distributions'][prop_key] )\n",
    "\n",
    "        return centers, dist\n",
    "\n",
    "    def get_estimate( variation, sl, prop_key ):\n",
    "\n",
    "        centers = copy.copy( absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key] )\n",
    "        dist = copy.copy( absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key] )\n",
    "\n",
    "        return centers, dist\n",
    "\n",
    "    fig_tuple = plot_violin( get_source, { variation: pm }, color='k', use_helper_colors=False, alpha=1, logscale_distributions=True )\n",
    "\n",
    "    fig_tuple = plot_violin( get_estimate, { variation: pm }, fig_tuple=fig_tuple, logscale_distributions=True )\n",
    "    \n",
    "    fig_tuple[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83a42e-209d-4f8f-b382-0b91d4735262",
   "metadata": {},
   "source": [
    "### Source Violin, Estimated Violin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a9f8a-5de3-4c1c-91e6-fe925b549ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source( variation, sl, prop_key ):\n",
    "    \n",
    "    if variation != 'original':\n",
    "        return None, None\n",
    "\n",
    "    pm = pms[variation]\n",
    "\n",
    "    centers = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['centers'][prop_key] )\n",
    "    dist = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['distributions'][prop_key] )\n",
    "\n",
    "    return centers, dist\n",
    "\n",
    "def get_estimate( variation, sl, prop_key ):\n",
    "    \n",
    "    pm = pms[variation]\n",
    "\n",
    "    centers = copy.copy( absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key] )\n",
    "    dist = copy.copy( absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key] )\n",
    "\n",
    "    return centers, dist\n",
    "\n",
    "fig_tuple = plot_violin( get_source, pms, color='k', use_helper_colors=False, alpha=1 )\n",
    "\n",
    "fig_tuple = plot_violin( get_estimate, pms, fig_tuple=fig_tuple )\n",
    "\n",
    "save_fp = os.path.join( pm['figure_dir'], 'violin.pdf' )\n",
    "plt.savefig( save_fp )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b35660-e668-48b2-b3ec-38e92097b118",
   "metadata": {},
   "source": [
    "### Source Violin, Estimated Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8923190-e4df-4deb-bf6a-cf3282f907e4",
   "metadata": {},
   "source": [
    "#### Scaled alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ce01e-e88a-40f8-b2d6-0a0d240e4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source( variation, sl, prop_key ):\n",
    "    \n",
    "    if variation != 'original':\n",
    "        return None, None\n",
    "\n",
    "    pm = pms[variation]\n",
    "\n",
    "    centers = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['centers'][prop_key] )\n",
    "    dist = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['distributions'][prop_key] )\n",
    "\n",
    "    return centers, dist\n",
    "\n",
    "fig, main_ax, ax_dict = plot_violin( get_source, pms, color='k', use_helper_colors=False, alpha=1, logscale_distributions=True, )\n",
    "\n",
    "# Plot individual components\n",
    "for ax_key, ax in ax_dict.items():\n",
    "    for variation, pm in pms.items():\n",
    "        for i, sl in enumerate( sls ):\n",
    "        \n",
    "            components = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['individual distributions']\n",
    "            centers = copy.copy( absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][ax_key] )\n",
    "            \n",
    "            if helpers.logscale[ax_key]:\n",
    "                centers = np.log10( centers )\n",
    "                \n",
    "            # Get alpha values for components.\n",
    "            # Logscaled, with a minimum alpha set immediately below\n",
    "            alpha_min = 0.5\n",
    "            norms = components.transpose().sum()[prop_key]\n",
    "            alphas = norms.apply( matplotlib.colors.LogNorm( norms.keymin()[1], norms.keymax()[1] ) )\n",
    "            alphas = alphas * ( 1. - alpha_min ) + alpha_min\n",
    "            \n",
    "            for comp_key, comp in components.items():\n",
    "                \n",
    "                mle = centers[comp[ax_key].argmax()]\n",
    "                \n",
    "                ax.scatter(\n",
    "                    xs[i] + variation_plotting_params[variation]['offset'] * ( xs[1] - xs[0] ),\n",
    "                    mle,\n",
    "                    color = helpers.colors_for_variations[variation],\n",
    "                    s = 100,\n",
    "                    edgecolor = 'w',\n",
    "                    linewidth = 1,\n",
    "                    alpha = alphas[comp_key],\n",
    "                )\n",
    "\n",
    "\n",
    "save_fp = os.path.join( pm['figure_dir'], 'violin_vs_components_alternate.pdf' )\n",
    "plt.savefig( save_fp )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed75e8f-a410-4fcf-80b2-d4f5dfb91b97",
   "metadata": {},
   "source": [
    "#### Scaled length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73d2dd-abe0-45a6-a9c4-e069248aae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source( variation, sl, prop_key ):\n",
    "    \n",
    "    if variation != 'original':\n",
    "        return None, None\n",
    "\n",
    "    pm = pms[variation]\n",
    "\n",
    "    centers = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['centers'][prop_key] )\n",
    "    dist = copy.copy( absorption_properties[pm['public_label']][sl]['data']['1D distributions']['distributions'][prop_key] )\n",
    "\n",
    "    return centers, dist\n",
    "\n",
    "fig, main_ax, ax_dict = plot_violin( get_source, pms, color='k', use_helper_colors=False, alpha=1, logscale_distributions=True, )\n",
    "\n",
    "# Plot individual components\n",
    "for ax_key, ax in ax_dict.items():\n",
    "    for variation, pm in pms.items():\n",
    "        for i, sl in enumerate( sls ):\n",
    "        \n",
    "            components = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['individual distributions']\n",
    "            centers = copy.copy( absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][ax_key] )\n",
    "            \n",
    "            if helpers.logscale[ax_key]:\n",
    "                centers = np.log10( centers )\n",
    "                \n",
    "            # Scale lines by component size, with minimum length\n",
    "            norms = components.transpose().sum()[prop_key]\n",
    "            length_min = 0.05\n",
    "            lengths = norms.apply( matplotlib.colors.LogNorm( norms.keymin()[1], norms.keymax()[1] ) )\n",
    "            alpha_min = 0.5\n",
    "            alphas = copy.deepcopy( lengths )\n",
    "            alphas = alphas * ( 1 - alpha_min ) + alpha_min\n",
    "            lengths = lengths * ( 1. - length_min ) + length_min\n",
    "            lengths *= helpers.violin_width * ( xs[1] - xs[0] )\n",
    "            \n",
    "            for comp_key, comp in components.items():\n",
    "                \n",
    "                mle = centers[comp[ax_key].argmax()]\n",
    "                \n",
    "                ax.plot(\n",
    "                    [ xs[i] - lengths[comp_key] / 2., xs[i] + lengths[comp_key] / 2. ],\n",
    "                    [ mle, ] * 2,\n",
    "                    color = helpers.colors_for_variations[variation],\n",
    "                    linewidth = 5,\n",
    "                    # alpha = alphas[comp_key],\n",
    "                )\n",
    "\n",
    "\n",
    "save_fp = os.path.join( pm['figure_dir'], 'violin_vs_components.pdf' )\n",
    "plt.savefig( save_fp )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4607e71-7d60-4bb7-a662-15892bd50233",
   "metadata": {},
   "source": [
    "## Shape comparison\n",
    "Fraction enclosed compared to fraction enclosed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3282a84a-bbdd-444f-a651-4954acdcc54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "f_estimated_to_enclose_f_data = verdict.Dict({})\n",
    "f_data_enclosed_by_f_estimated = verdict.Dict({})\n",
    "dist_comparison_figs = []\n",
    "for i, sl in enumerate( sls ):\n",
    "\n",
    "    # Setup figure\n",
    "    fig = plt.figure()\n",
    "    main_ax = plt.gca()\n",
    "    main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "    for spine in main_ax.spines.values():\n",
    "        spine.set_visible( False )\n",
    "\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        mosaic_dist,\n",
    "    )\n",
    "\n",
    "    main_ax.set_xlabel( '% of likelihood distribution enclosed', labelpad=30 )\n",
    "    main_ax.set_ylabel( '% of synthetic data enclosed', labelpad=30 )\n",
    "\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "        ax.set_xlim( 0, 100 )\n",
    "        ax.set_ylim( 0, 100 )\n",
    "\n",
    "        ax.annotate(\n",
    "            text = helpers.property_labels_no_units[ax_key],\n",
    "            xy = ( 0, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( 5, -5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'left',\n",
    "        )\n",
    "        \n",
    "        ax.plot(\n",
    "            [ 0, 100 ],\n",
    "            [ 0, 100 ],\n",
    "            color = '0.5',\n",
    "            linewidth = 1.5,\n",
    "            zorder = -110,\n",
    "        )\n",
    "\n",
    "    main_ax.set_title(\n",
    "        label = sl,\n",
    "        loc = 'right',\n",
    "    )\n",
    "\n",
    "    for variation, pm in pms.items():\n",
    "\n",
    "        for prop_key in absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'].keys():\n",
    "\n",
    "            # Get plot panel\n",
    "            ax = ax_dict[prop_key]\n",
    "            subplotspec = ax.get_subplotspec()\n",
    "\n",
    "            # Get data distributions\n",
    "            centers_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'][prop_key]\n",
    "            dist_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['distributions'][prop_key]\n",
    "            dist_data_sum = dist_data.sum()\n",
    "\n",
    "            # Get modeled distributions\n",
    "            centers_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key]\n",
    "            bins_estimated = np.full( centers_estimated.shape, np.nan )\n",
    "            bin_widths = np.diff( centers_estimated )\n",
    "            bins_estimated[0:centers_estimated.size-1] = centers_estimated[:-1] - bin_widths / 2.\n",
    "            bins_estimated[centers_estimated.size-1] = centers_estimated[-1] + bin_widths[-1] / 2.\n",
    "            dist_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key]\n",
    "            dist_estimated_sum = dist_estimated.sum()\n",
    "            max_ind_estimated = dist_estimated.argmax()\n",
    "\n",
    "            # Calculate fraction included arrays\n",
    "            j = 0\n",
    "            f_included_data = []\n",
    "            f_included_estimated = []\n",
    "            while True:\n",
    "\n",
    "                # Get range to include\n",
    "                left = max_ind_estimated - j\n",
    "                right = max_ind_estimated + j + 1\n",
    "\n",
    "                # Check if looping is done\n",
    "                left_in_bounds = left >= 0\n",
    "                right_in_bounds = right < centers_estimated.size\n",
    "                continue_looping = left_in_bounds or right_in_bounds\n",
    "                if not continue_looping:\n",
    "                    break\n",
    "                    \n",
    "                if not left_in_bounds:\n",
    "                    left = 0\n",
    "                if not right_in_bounds:\n",
    "                    right = centers_estimated.size - 1\n",
    "\n",
    "                # Get fraction included\n",
    "                x_value_left = bins_estimated[left]\n",
    "                x_value_right = bins_estimated[right]\n",
    "                is_in_range_data = ( centers_data > x_value_left ) & (centers_data < x_value_right )\n",
    "\n",
    "                f_included_data.append( dist_data[is_in_range_data].sum() / dist_data_sum )\n",
    "                f_included_estimated.append( dist_estimated[left:right].sum() / dist_estimated_sum )\n",
    "\n",
    "                j += 1\n",
    "            f_included_data = np.array( f_included_data )\n",
    "            f_included_estimated = np.array( f_included_estimated )\n",
    "            \n",
    "            # Extract a summary statistic\n",
    "            interp_data_estimated = scipy.interpolate.interp1d( f_included_data, f_included_estimated )\n",
    "            interp_estimated_data = scipy.interpolate.interp1d( f_included_estimated, f_included_data )\n",
    "            for fraction in pm['f_enclosed']:\n",
    "                \n",
    "                ## Fraction needed to enclose\n",
    "                try:\n",
    "                    f_to_enclose = interp_data_estimated( fraction )\n",
    "                    \n",
    "                    # If a value of 1 is needed, then the distribution doesn't actually enclose the data.\n",
    "                    if np.isclose( f_to_enclose, 1. ):\n",
    "                        f_to_enclose = np.nan\n",
    "                # If above or below the interpolation range\n",
    "                except ValueError:\n",
    "                    # If below, that means the fraction was reached with the first cell\n",
    "                    if fraction <= f_included_data[0]:\n",
    "                        f_to_enclose = f_included_estimated[0]\n",
    "                    # If above, then invalid\n",
    "                    elif fraction >= f_included_data[-1]:\n",
    "                        f_to_enclose = np.nan\n",
    "                f_estimated_to_enclose_f_data.setitem( pm['public_label'], f_to_enclose, prop_key, str( fraction ), sl )\n",
    "                \n",
    "                ## Fraction enclosed by a fixed value\n",
    "                try:\n",
    "                    f_data_enclosed = interp_estimated_data( fraction )\n",
    "                # If above or below the interpolation range\n",
    "                except ValueError:\n",
    "                    # If below the interpolation range, then f_estimated jumps sharply early, so the enclosed amount is just the first entry in f_included_data\n",
    "                    if fraction < f_included_estimated[0]:\n",
    "                        f_data_enclosed = f_included_data[0]\n",
    "                    # If above the interpolation range, then invalid\n",
    "                    if fraction >= f_included_estimated[-1]:\n",
    "                        f_data_enclosed = np.nan\n",
    "                f_data_enclosed_by_f_estimated.setitem( pm['public_label'], f_data_enclosed, prop_key, str( fraction ), sl )\n",
    "\n",
    "            ax.plot(\n",
    "                f_included_estimated * 100,\n",
    "                f_included_data * 100,\n",
    "                color = helpers.colors_for_variations[pm['variation']],\n",
    "            )\n",
    "            \n",
    "    dist_comparison_figs.append( fig )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad6dee-3e03-466a-b7cc-24ea820403f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_comparison_figs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087b92c-644b-445e-9e2f-5c494763930f",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30080e62-61da-44b7-b857-5aa6901b919e",
   "metadata": {},
   "source": [
    "## Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdca93e-9ed4-4070-8735-705eea90e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = verdict.Dict({})\n",
    "distances_between = verdict.Dict({})\n",
    "percentiles = verdict.Dict({})\n",
    "for i, sl in enumerate( sls ):\n",
    "\n",
    "    for prop_key in absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'].keys():\n",
    "\n",
    "        # Get plot panel\n",
    "        ax = ax_dict[prop_key]\n",
    "        subplotspec = ax.get_subplotspec()\n",
    "\n",
    "        for fraction in pm['f_enclosed']:\n",
    "            \n",
    "            for variation, pm in pms.items():\n",
    "                \n",
    "                # Get data distributions\n",
    "                centers_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['centers'][prop_key]\n",
    "                if helpers.logscale[prop_key]:\n",
    "                    centers_data = np.log10( centers_data )\n",
    "                dist_data = absorption_properties[pm['public_label']][sl]['source']['1D distributions']['distributions'][prop_key]\n",
    "                dist_data_sum = dist_data.sum()\n",
    "                cdf_data = np.cumsum( dist_data ) / dist_data_sum\n",
    "                interp_data = scipy.interpolate.interp1d( cdf_data, centers_data )\n",
    "\n",
    "                # Calculate data average\n",
    "                avg_data = interp_data( 0.5 )\n",
    "                averages.setitem( pm['public_label'], avg_data, 'source', prop_key, sl )\n",
    "\n",
    "               # Calculate data percentiles\n",
    "                interval_data = np.array([ interp_data( fraction / 2. ), interp_data( 1. - fraction / 2. ) ])\n",
    "                width_data = interval_data[1] - interval_data[0]\n",
    "                percentiles.setitem( pm['public_label'], interval_data, 'source', prop_key, str( fraction ), 'interval', sl )\n",
    "                percentiles.setitem( pm['public_label'], width_data, 'source', prop_key, str( fraction ), 'width', sl )\n",
    "\n",
    "\n",
    "                # Get modeled distributions\n",
    "                centers_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['centers'][prop_key]\n",
    "                if helpers.logscale[prop_key]:\n",
    "                    centers_estimated = np.log10( centers_estimated )\n",
    "                dist_estimated = absorption_properties[pm['public_label']][sl]['estimated']['1D distributions']['combined distributions'][prop_key]\n",
    "                dist_estimated_sum = dist_estimated.sum()\n",
    "                cdf_estimated = np.cumsum( dist_estimated ) / dist_estimated_sum\n",
    "                interp_estimated = scipy.interpolate.interp1d( cdf_estimated, centers_estimated )\n",
    "                \n",
    "                # Calculate MLE and averages\n",
    "                x_max = centers_estimated[np.argmax( dist_estimated )]\n",
    "                x_avg = interp_estimated( 0.5 )\n",
    "                averages.setitem( pm['public_label'], x_max, 'estimated', 'MLE', prop_key, sl )\n",
    "                averages.setitem( pm['public_label'], x_avg, 'estimated', 'average', prop_key, sl )\n",
    "\n",
    "                # Calculate parameter estimation percentiles\n",
    "                alpha = 1 - fraction\n",
    "                interval = np.array([ interp_estimated( alpha / 2. ), interp_estimated( 1. - alpha / 2. ) ])\n",
    "                width = interval[1] - interval[0]\n",
    "                percentiles.setitem( pm['public_label'], interval, 'estimated', prop_key, str( fraction ), 'interval', sl )\n",
    "                percentiles.setitem( pm['public_label'], width, 'estimated', prop_key, str( fraction ), 'width', sl )\n",
    "\n",
    "                # Calculate necessary width\n",
    "                width_necessary = np.max( np.abs( interval_data - x_max ) )\n",
    "                width_between_peaks = np.abs( avg_data - x_max )\n",
    "                distances_between.setitem( pm['public_label'], width_necessary, prop_key, 'distance_to_enclose', str( fraction ), sl )\n",
    "                distances_between.setitem( pm['public_label'], width_between_peaks, prop_key, 'distance_to_avg', sl )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331e51b-cd38-4afc-8d23-d7d0656763cc",
   "metadata": {},
   "source": [
    "## Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0142080-2bec-49b0-8e7a-54b1fb6b266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric( get_ys, fig_tuple=None, **scatter_kwargs ):\n",
    "    \n",
    "    if fig_tuple is None:\n",
    "        # Setup figure\n",
    "        n_rows = len( mosaic_dist )\n",
    "        n_cols = len( mosaic_dist[0] )\n",
    "        fig = plt.figure( figsize=(n_cols*helpers.figure_width, n_rows*helpers.figure_height), facecolor='w' )\n",
    "        main_ax = plt.gca()\n",
    "        main_ax.tick_params( left=False, labelleft=False, bottom=False, labelbottom=False )\n",
    "        for spine in main_ax.spines.values():\n",
    "            spine.set_visible( False )\n",
    "\n",
    "        ax_dict = fig.subplot_mosaic(\n",
    "            mosaic_dist,\n",
    "            gridspec_kw = { 'hspace': 0.15, 'wspace': 0.12 },\n",
    "        )\n",
    "    else:\n",
    "        fig, main_ax, ax_dict = fig_tuple\n",
    "    \n",
    "    # Axes tweaks\n",
    "    for ax_key, ax in ax_dict.items():\n",
    "\n",
    "        ax.set_xticks( xs )\n",
    "        xtick_labels = [ _[-2:] for _ in sls ]\n",
    "        ax.set_xticklabels( xtick_labels )\n",
    "        \n",
    "        # Axes tweaks\n",
    "        axis_label = helpers.property_labels_no_units[ax_key]\n",
    "        if helpers.logscale[ax_key]:\n",
    "            axis_label = 'log' + axis_label\n",
    "\n",
    "        ax.annotate(\n",
    "            text = axis_label,\n",
    "            xy = ( 0, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( 5, -5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'left',\n",
    "        )\n",
    "        \n",
    "    for variation, pm in pms.items():\n",
    "\n",
    "        for ax_key, ax in ax_dict.items():\n",
    "        \n",
    "            ys = get_ys( variation=variation, prop_key=ax_key )\n",
    "            if ys is None:\n",
    "                continue\n",
    "            \n",
    "            color = helpers.colors_for_variations[pm['variation']]\n",
    "            fill_color = color\n",
    "            used_scatter_kwargs = dict(\n",
    "                s = 100,\n",
    "                edgecolor = color,\n",
    "                color = fill_color,\n",
    "            )\n",
    "            used_scatter_kwargs.update( scatter_kwargs )\n",
    "\n",
    "            scatter = ax.scatter(\n",
    "                xs,\n",
    "                ys,\n",
    "                **used_scatter_kwargs\n",
    "            )\n",
    "    \n",
    "    return fig, main_ax, ax_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c3b61-2730-4c46-b3d0-0b83bad3c4cc",
   "metadata": {},
   "source": [
    "## MLEs and Average Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafa17b-74ca-49cd-891a-300f4140c49e",
   "metadata": {},
   "source": [
    "### Straight-up values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb76e1c-cfbb-4f88-bd02-501f45a4d1fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_estimated_ys( variation, prop_key ):\n",
    "\n",
    "    pm = pms[variation]\n",
    "\n",
    "    mle = averages[pm['public_label']]['estimated']['MLE'][prop_key].array()\n",
    "    return mle\n",
    "\n",
    "fig, main_ax, ax_dict = plot_metric( get_estimated_ys )\n",
    "\n",
    "def get_source_ys( variation, prop_key ):\n",
    "    \n",
    "    if variation != 'original':\n",
    "        return None\n",
    "\n",
    "    pm = pms[variation]\n",
    "\n",
    "    avg = averages[pm['public_label']]['source'][prop_key].array()\n",
    "    return avg\n",
    "\n",
    "fig, main_ax, ax_dict = plot_metric( get_source_ys, ( fig, main_ax, ax_dict ), marker='x', color='k', )\n",
    "\n",
    "# Axes tweaks\n",
    "for ax_key, ax in ax_dict.items():         \n",
    "    ylims = helpers.lims[ax_key]\n",
    "    if helpers.logscale[ax_key]:\n",
    "        ylims = np.log10( ylims )\n",
    "\n",
    "    ax.set_ylim( ylims )\n",
    "\n",
    "main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "main_ax.set_ylabel( r'$x_{\\rm MLE}$', labelpad=40 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47106b2-288a-4b51-9883-2d71111c28ad",
   "metadata": {},
   "source": [
    "### Difference between values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544bff7-3e98-4669-b88c-6b77e8b07527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ys( variation, prop_key ):\n",
    "\n",
    "    pm = pms[variation]\n",
    "\n",
    "    d_between = distances_between[pm['public_label']][prop_key]['distance_to_avg'].array()\n",
    "    return d_between\n",
    "\n",
    "fig, main_ax, ax_dict = plot_metric( get_ys )\n",
    "\n",
    "main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "main_ax.set_ylabel( r'$\\left| x_{\\rm MLE} - \\langle x \\rangle \\right|$', labelpad=30 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc4218-1a28-4fb2-9e5c-9767e83f60fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Distribution Widths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9b09e-760c-4a8b-803d-289163eac1f0",
   "metadata": {},
   "source": [
    "### Scaled by error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f371a-f251-418c-958f-5f4fe6c418c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fraction in pm['f_enclosed']:\n",
    "    \n",
    "    def get_widths( variation, prop_key ):\n",
    "        \n",
    "        pm = pms[variation]\n",
    "        \n",
    "        percentile = percentiles[pm['public_label']]['estimated'][prop_key][str(fraction)]['width'].array()\n",
    "        d_between = distances_between[pm['public_label']][prop_key]['distance_to_avg'].array()\n",
    "        \n",
    "        if helpers.logscale[prop_key]:\n",
    "            return percentile - d_between\n",
    "        else:\n",
    "            return percentile / d_between\n",
    "    \n",
    "    fig, main_ax, ax_dict = plot_metric( get_widths )\n",
    "    \n",
    "    for ax_key, ax in ax_dict.items():\n",
    "        \n",
    "        hline = 1\n",
    "        \n",
    "        if helpers.logscale[ax_key]:\n",
    "            hline = np.log10( hline )\n",
    "            \n",
    "        ax.axhline( hline, color='0.5', )\n",
    "\n",
    "    main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "    main_ax.set_ylabel( '{}'.format( int( fraction * 100 ) ) + r'th percentile / $\\left| x_{\\rm MLE} - \\langle x \\rangle \\right|$', labelpad=60 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5499e0-5928-46de-80e0-e0ad06e1c158",
   "metadata": {},
   "source": [
    "### Scaled by distance to enclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e11855-078d-4037-bc26-b0168b9ef8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fraction in pm['f_enclosed']:\n",
    "    \n",
    "    def get_widths( variation, prop_key ):\n",
    "        \n",
    "        pm = pms[variation]\n",
    "        \n",
    "        percentile = percentiles[pm['public_label']]['estimated'][prop_key][str(fraction)]['width'].array()\n",
    "        d_between = distances_between[pm['public_label']][prop_key]['distance_to_enclose'][str(fraction)].array()\n",
    "        \n",
    "        if helpers.logscale[prop_key]:\n",
    "            return percentile - d_between\n",
    "        else:\n",
    "            return percentile / d_between\n",
    "    \n",
    "    fig, main_ax, ax_dict = plot_metric( get_widths )\n",
    "    \n",
    "    for ax_key, ax in ax_dict.items():\n",
    "        \n",
    "        hline = 1\n",
    "        \n",
    "        if helpers.logscale[ax_key]:\n",
    "            hline = np.log10( hline )\n",
    "            \n",
    "        ax.axhline( hline, color='0.5', )\n",
    "\n",
    "    main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "    main_ax.set_ylabel( '{}'.format( int( fraction * 100 ) ) + r'th percentile / $\\left| x_{\\rm MLE} - x_{' + '{}'.format( int( fraction * 100 ) ) + r'} \\right|$', labelpad=60 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f7b75-4ce9-4189-b8ca-58050a01a738",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fraction enclosed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af2a85-ce7e-4998-8fcb-ce22b2ac811e",
   "metadata": {},
   "source": [
    "### % of likelihood to enclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe589659-8e31-454f-9861-7bcd303c9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fraction in pm['f_enclosed']:\n",
    "    \n",
    "    def get_ys( variation, prop_key ):\n",
    "        \n",
    "        pm = pms[variation]\n",
    "        \n",
    "        ys = f_estimated_to_enclose_f_data[pm['public_label']][prop_key][str(fraction)].array() * 100\n",
    "        \n",
    "        return ys\n",
    "    \n",
    "    fig, main_ax, ax_dict = plot_metric( get_ys )\n",
    "    \n",
    "    for ax_key, ax in ax_dict.items():\n",
    "        \n",
    "        ax.set_ylim( 0, 100 )\n",
    "        \n",
    "        hline = fraction * 100\n",
    "            \n",
    "        ax.axhline( hline, color='0.5', )\n",
    "\n",
    "    main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "    main_ax.set_ylabel( '% of likelihood to enclose {}% of the data'.format( int( fraction * 100 ) ), labelpad=60 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29745d-f02a-4495-8176-525445c811a8",
   "metadata": {},
   "source": [
    "### % of data enclosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b91bf-10fc-467c-ba28-59d59c957215",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fraction in pm['f_enclosed']:\n",
    "    \n",
    "    def get_ys( variation, prop_key ):\n",
    "        \n",
    "        pm = pms[variation]\n",
    "        \n",
    "        ys = f_data_enclosed_by_f_estimated[pm['public_label']][ax_key][str(fraction)].array() * 100\n",
    "        \n",
    "        return ys\n",
    "    \n",
    "    fig, main_ax, ax_dict = plot_metric( get_ys )\n",
    "    \n",
    "    for ax_key, ax in ax_dict.items():\n",
    "        \n",
    "        ax.set_ylim( 0, 100 )\n",
    "        \n",
    "        hline = fraction * 100\n",
    "            \n",
    "        ax.axhline( hline, color='0.5', )\n",
    "\n",
    "    main_ax.set_xlabel( 'sightline ID', labelpad=30 )\n",
    "    main_ax.set_ylabel( '% of data enclosed by {}% of the likelihood'.format( int( fraction * 100 ) ), labelpad=30 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970c7c2-60fc-4868-bdee-1d4bf2048b2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50461f2f-f186-452a-8a09-302cc6062d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Figure\n",
    "n_rows = len( mosaic_dist )\n",
    "n_cols = len( mosaic_dist[0] )\n",
    "fig = plt.figure( figsize=(n_cols*helpers.figure_width, n_rows*helpers.figure_height), facecolor='w' )\n",
    "ax_dict = fig.subplot_mosaic(\n",
    "    mosaic_dist,\n",
    "    gridspec_kw = { 'wspace': 0.7 },\n",
    ")\n",
    "ax_dict['legend'] = ax_dict['vlos']\n",
    "\n",
    "def r_scatter( ax, ys, c_key, color=None, label_tag=None ):\n",
    "    c_params = helpers.correlation_coefficients[c_key]\n",
    "    if 'logscale' in c_params:\n",
    "        if c_params['logscale']:\n",
    "            facecolors = 'none'\n",
    "    else:\n",
    "        facecolors = color\n",
    "        \n",
    "    scatter = ax.scatter(\n",
    "        xs,\n",
    "        ys,\n",
    "        label = '{}, {}'.format( label_tag, c_key ),\n",
    "        edgecolors = color,\n",
    "        facecolors = facecolors,\n",
    "        marker = correlation_markers[c_key],\n",
    "        s = correlation_sizes[c_key],\n",
    "        linewidth = 2,\n",
    "    )\n",
    "\n",
    "    \n",
    "# Overall\n",
    "for variation, pm in pms.items():\n",
    "    \n",
    "    correlations = correlations_all[pm['public_label']]\n",
    "    plotting_params = variation_plotting_params[variation]\n",
    "    \n",
    "    # for c_key in correlations_plotted:\n",
    "    #     r_scatter(\n",
    "    #         ax_dict['all'],\n",
    "    #         correlations[c_key]['ndim'].array(),\n",
    "    #         c_key,\n",
    "    #         color = plotting_params['color'],\n",
    "    #     )\n",
    "\n",
    "    # Each property\n",
    "    for j, x_key in enumerate( tqdm.tqdm( pm['prop_keys'], bar_format=pm['bar_format'] ) ):\n",
    "\n",
    "        ax = ax_dict[x_key]\n",
    "\n",
    "        for c_key in correlations_plotted:\n",
    "            r_scatter(\n",
    "                ax,\n",
    "                correlations[c_key]['matrix'].array()[:,j,j],\n",
    "                c_key,\n",
    "                color = plotting_params['color'],\n",
    "                label_tag = plotting_params['label'],\n",
    "            )\n",
    "    \n",
    "        \n",
    "# Add a legend\n",
    "h, l = ax_dict['vlos'].get_legend_handles_labels()\n",
    "legend = ax_dict['legend'].legend(\n",
    "    h,\n",
    "    l,\n",
    "    loc = 'lower left',\n",
    "    prop = {'size': 14},\n",
    "    ncol = 2,\n",
    "    framealpha = 1,\n",
    ")\n",
    "# ax_dict['legend'].axis( 'off' )\n",
    "# ax_dict['legend'].annotate(\n",
    "#     text = r'$r = \\frac{ \\langle {\\rm actual } \\vert  {\\rm found } \\rangle }{ \\vert {\\rm actual} \\vert \\vert {\\rm found } \\vert }$',\n",
    "#     xy = ( 0, 1 ),\n",
    "#     xycoords = 'axes fraction',\n",
    "#     xytext = ( 5, -5 ),\n",
    "#     textcoords = 'offset points',\n",
    "#     ha = 'center',\n",
    "#     va = 'top',\n",
    "#     fontsize = 18,\n",
    "# )\n",
    "        \n",
    "# Cleanup\n",
    "for x_key, ax in ax_dict.items():\n",
    "    \n",
    "    if x_key in [ 'legend', 'empty' ]:\n",
    "        continue\n",
    "    \n",
    "    subplotspec = ax.get_subplotspec()\n",
    "    \n",
    "    for value in [ -1, 0, 1 ]:\n",
    "        ax.axhline(\n",
    "            value,\n",
    "            color = pm['background_linecolor'],\n",
    "            linewidth = 1,\n",
    "            zorder = -100,\n",
    "        )\n",
    "        \n",
    "    ax.set_ylabel( helpers.correlation_coefficient_property_labels[x_key], fontsize=16 )\n",
    "    if subplotspec.is_last_row():\n",
    "        ax.set_xlabel( 'sightline ID', fontsize=16 )\n",
    "        \n",
    "    ax.set_xticks( xs )\n",
    "    xtick_labels = [ _[-2:] for _ in correlations[c_key]['ndim'].keys_array() ]\n",
    "    ax.set_xticklabels( xtick_labels )\n",
    "        \n",
    "    ax.set_ylim( -0.3, 1.1 )\n",
    "    \n",
    "# Save\n",
    "savedir = pm['figure_dir']\n",
    "os.makedirs( savedir, exist_ok=True )\n",
    "savefile = 'correlations.pdf'\n",
    "save_fp = os.path.join( savedir, savefile )\n",
    "print( 'Saving figure to {}'.format( save_fp ) )\n",
    "plt.savefig( save_fp, bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754b996-3aeb-4c42-8cc8-a7badc8c03bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
