{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import h5py\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.interpolate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Currently need to call this to get matplotlib selected style to load...\n",
    "plt.plot()\n",
    "matplotlib.style.use( '/Users/zhafen/repos/clean-bold/clean-bold-mnras.mplstyle' )\n",
    "import palettable\n",
    "import matplotlib.patheffects as path_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import trident\n",
    "import unyt as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kalepy as kale\n",
    "import verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "seed = 15482\n",
    "rng = np.random.default_rng( seed )\n",
    "verbose = False\n",
    "Z_sun = 0.014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management parameters\n",
    "distribution_fp = './data/EAGLE/histogram_galaxies_logM200c-Msun-12.0-12.5_200_seed0_hneutralssh.hdf5'\n",
    "data_dir = './data/synthetic_data/sample1'\n",
    "observer_data_dir = './data/synthetic_data_samples/sample1'\n",
    "summary_data_fp = './data/polished_data/summary.h5'\n",
    "figure_dir = '/Users/zhafen/drafts/cgm_modeling_challenge_paper/figures/sample1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs( figure_dir, exist_ok=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray parameters\n",
    "redshift = 0.25\n",
    "n_sightlines = 100\n",
    "min_clouds_per_sightline = 1\n",
    "max_clouds_per_sightline = 3\n",
    "velocity_range = [ -150., 150. ] # In km/s\n",
    "finite_cloud_max_logT = 5 # We'll only allow one cloud per line of sight with temperatures greater than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectra parameters\n",
    "ions = [\n",
    "    'H I',\n",
    "    'O I',\n",
    "    'C II',\n",
    "    'C III',\n",
    "    'N II',\n",
    "    'N III',\n",
    "    'Si II',\n",
    "    'Si III',\n",
    "    'Si IV',\n",
    "#     'N V',\n",
    "    'O VI',\n",
    "    'Mg II'\n",
    "]\n",
    "fields = [\n",
    "    'H_p0_number_density', \n",
    "    'O_p0_number_density',\n",
    "    'C_p1_number_density',\n",
    "    'C_p2_number_density',\n",
    "    'N_p1_number_density',\n",
    "    'N_p2_number_density',\n",
    "    'Si_p1_number_density',\n",
    "    'Si_p2_number_density',\n",
    "    'Si_p3_number_density',\n",
    "#     'N_p4_number_density',\n",
    "    'O_p5_number_density',\n",
    "    'Mg_p1_number_density'\n",
    "]\n",
    "plotted_ions = [\n",
    "    'H I 923',\n",
    "    'H I 926',\n",
    "    'H I 930',\n",
    "    'H I 937',\n",
    "    'H I 949',\n",
    "    'H I 972',\n",
    "    'H I 1025',\n",
    "    'H I 1215',\n",
    "    'Si II 1020',\n",
    "    'Si II 1190',\n",
    "    'Si II 1193',\n",
    "    'Si II 1260',\n",
    "    'Si II 1304',\n",
    "    'Si III 1206',\n",
    "    'Si IV 1393',\n",
    "    'Si IV 1402',\n",
    "    'C II 1036',\n",
    "    'C II 1334',\n",
    "    'C III 977',\n",
    "    'N II 1083',\n",
    "    'N III 989',\n",
    "    'N V 1238',\n",
    "    'N V 1242',\n",
    "    'O I 1302',\n",
    "    'O VI 1031',\n",
    "    'O VI 1037',\n",
    "    'Mg II 2796',\n",
    "    'Mg II 2803',\n",
    "]\n",
    "snr = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "colors = palettable.cartocolors.qualitative.Safe_10.mpl_colors\n",
    "modeled_color = palettable.cartocolors.qualitative.Safe_10.mpl_colors[1]\n",
    "revised_color = palettable.cartocolors.qualitative.Safe_10.mpl_colors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_data_dir = './data/modeling_results/sameer_charlton/sample1/pdfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a dictionary\n",
    "modeled = {}\n",
    "for dirname in tqdm.tqdm( os.listdir( modeled_data_dir ) ):\n",
    "        \n",
    "    # Get dirs, skip others\n",
    "    current_dir = os.path.join( modeled_data_dir, dirname )\n",
    "    if not os.path.isdir( current_dir ):\n",
    "        continue\n",
    "        \n",
    "    modeled_dir = {}\n",
    "    for file in os.listdir( current_dir ):\n",
    "        comp_key = file.split( '.' )[0]\n",
    "        \n",
    "        fp = os.path.join( current_dir, file )\n",
    "        df = pd.read_csv( fp, sep=' ', header=None, )\n",
    "        df.columns = [ 'Prob', 'Likelihood', 'logZ', 'logT', 'lognH' ]\n",
    "        \n",
    "        modeled_dir[comp_key] = df\n",
    "        \n",
    "    modeled[dirname[:3]] = modeled_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate histograms, and store in a format conducive to plotting\n",
    "sl_keys = sorted( list( modeled.keys() ) )\n",
    "params = [ 'logZ', 'logT', 'lognH' ]\n",
    "dx = 0.0\n",
    "dists = {}\n",
    "for param in params:\n",
    "    \n",
    "    param_dists = {\n",
    "        'xs': [],\n",
    "        'values': [],\n",
    "        'mles': [],\n",
    "        'sls': [],\n",
    "        'comps': [],\n",
    "    }\n",
    "    for i, sl in enumerate( tqdm.tqdm( sl_keys ) ):\n",
    "        \n",
    "        for j, ( comp_key, df ) in enumerate( modeled[sl].items() ):\n",
    "            \n",
    "            values = df[param].values\n",
    "            \n",
    "            x = i + j*dx\n",
    "            \n",
    "            kde = kale.kde.KDE( values )\n",
    "            centers, pdf = kde.density()\n",
    "            mle = centers[pdf.argmax()]\n",
    "            \n",
    "            param_dists['xs'].append( x )\n",
    "            param_dists['values'].append( values )\n",
    "            param_dists['mles'].append( mle )\n",
    "            param_dists['sls'].append( sl )\n",
    "            param_dists['comps'].append( comp_key )\n",
    "            \n",
    "    dists[param] = param_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of components\n",
    "n_comp_modeled = [ len( modeled[sl].keys() ) for sl in sl_keys ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sls = verdict.Dict.from_hdf5( './data/synthetic_data/sample1/sightlines.h5', jagged_flag='sl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = {}\n",
    "for key, item in sls.items():\n",
    "    clouds[key] = np.concatenate( item )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used sightlines\n",
    "indices = np.array( sl_keys ).astype( int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particular sightlines chosen\n",
    "combined = {\n",
    "    'logZ': [],\n",
    "    'logT': [],\n",
    "    'lognH': [],\n",
    "}\n",
    "for i in indices:\n",
    "    \n",
    "    print( 'Sightline {:03d}'.format( i ) )\n",
    "\n",
    "    density = 10.**sls['Density'][i] * u.g * u.cm**-3 / u.mp * 0.75\n",
    "    temperature = 10.**sls['Temperature'][i] * u.K\n",
    "    metallicity = 10.**sls['Metallicity'][i] / Z_sun\n",
    "    HI_column = 10.**sls['HI Column'][i] * u.cm**-2\n",
    "    velocity = sls['LOS Velocity'][i] * u.km / u.s\n",
    "    lengths = sls['Lengths'][i] * u.cm\n",
    "    \n",
    "    for j, den in enumerate( density ):\n",
    "        \n",
    "        print( '    logZ = {:.3g}, logT = {:.3g}, logn = {:.3g}'.format( \n",
    "                np.log10( metallicity[j] ),\n",
    "                np.log10( temperature[j] ),\n",
    "                np.log10( den ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if len( velocity ) == 2:\n",
    "        print( '    delta_v = {:.3g}'.format( np.abs( velocity[1] - velocity[0] ) ) )\n",
    "    \n",
    "    den = ( density * lengths ).sum() / lengths.sum()\n",
    "    temp = ( temperature * density * lengths ).sum() / ( density * lengths ).sum()\n",
    "    met = ( metallicity * Z_sun * density * lengths ).sum() / ( Z_sun * density * lengths ).sum()\n",
    "    print( '    Combined, logZ = {:.3g}, logT = {:.3g}, logn = {:.3g}'.format( \n",
    "            np.log10( met ),\n",
    "            np.log10( temp ),\n",
    "            np.log10( den ),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    combined['lognH'].append( den )\n",
    "    combined['logZ'].append( met )\n",
    "    combined['logT'].append( temp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mapping = {\n",
    "    'logZ': 'Metallicity',\n",
    "    'logT': 'Temperature',\n",
    "    'lognH': 'Density',\n",
    "}\n",
    "x_labels = {\n",
    "    'logZ': r'$\\log_{10} Z / Z_\\odot$',\n",
    "    'logT': r'$\\log_{10} T / K$',\n",
    "    'lognH': r'$\\log_{10} n_{\\rm H} / {\\rm cm}^{-3}$',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_width = plt.rcParams['figure.figsize'][0]\n",
    "fig = plt.figure( figsize=( panel_width, panel_width*len( x_labels )/2. ), facecolor='w' )\n",
    "# ax_main = plt.gca()\n",
    "\n",
    "gs = matplotlib.gridspec.GridSpec( 3, 1 )\n",
    "# gs.update( hspace=0.1)\n",
    "\n",
    "main_xs = np.arange( len( indices ) )\n",
    "\n",
    "for i, param in enumerate( params ):\n",
    "    ax = fig.add_subplot( gs[i,0] )\n",
    "    \n",
    "#     # Combined\n",
    "#     ax.scatter(\n",
    "#         main_xs,\n",
    "#         np.log10( combined[param] ),\n",
    "#         color = 'none',\n",
    "#         edgecolor = 'k',\n",
    "#         s = 200,\n",
    "#         zorder = 100,\n",
    "#     )\n",
    "\n",
    "    # Individual clouds\n",
    "    for i, ind in enumerate( indices ):\n",
    "\n",
    "        if param == 'logZ':\n",
    "            ys = np.log10( 10.**sls[param_mapping[param]][ind] / Z_sun )\n",
    "        elif param == 'lognH':\n",
    "            ys = np.log10( 10.**sls[param_mapping[param]][ind] * u.g * u.cm**-3 / u.mp * 0.75 )\n",
    "        else:\n",
    "            ys = sls[param_mapping[param]][ind]\n",
    "\n",
    "        xs = np.full( ys.size, i )\n",
    "        ax.scatter(\n",
    "            xs,\n",
    "            ys,\n",
    "            color = 'k',\n",
    "            zorder = 90,\n",
    "            edgecolor = 'k',\n",
    "            linewidth = 0.2,\n",
    "            s = 25,\n",
    "        )\n",
    "        \n",
    "        ax.annotate(\n",
    "            text = '{}'.format( ys.size ),\n",
    "            xy = (i, 1),\n",
    "            xycoords = matplotlib.transforms.blended_transform_factory( ax.transData, ax.transAxes ),\n",
    "            xytext = ( -1, 2.5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'bottom',\n",
    "            ha = 'right',\n",
    "            fontsize = 'small',\n",
    "            fontweight = 'bold',\n",
    "        )\n",
    "    \n",
    "    # Annotate number of modeled components\n",
    "    ax.annotate(\n",
    "        text = r'$n_{\\rm comp}:$',\n",
    "        xy = ( 0, 1 ),\n",
    "        xycoords = 'axes fraction',\n",
    "        xytext = ( 0, 2.5 ),\n",
    "        textcoords = 'offset points',\n",
    "        fontsize = 'small',\n",
    "        va = 'bottom',\n",
    "        ha = 'right',\n",
    "        fontweight = 'bold',\n",
    "    )\n",
    "    for i, n_comp in enumerate( n_comp_modeled ): \n",
    "        ax.annotate(\n",
    "            text = '{}'.format( n_comp ),\n",
    "            xy = (i, 1),\n",
    "            xycoords = matplotlib.transforms.blended_transform_factory( ax.transData, ax.transAxes ),\n",
    "            xytext = ( 1, 2.5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'bottom',\n",
    "            ha = 'left',\n",
    "            fontsize = 'small',\n",
    "            color = modeled_color,\n",
    "            fontweight = 'bold',\n",
    "        )\n",
    "        \n",
    "    # Violin plot\n",
    "    v = ax.violinplot(\n",
    "        dists[param]['values'],\n",
    "        dists[param]['xs'],\n",
    "        showextrema = False,\n",
    "        widths = 0.75,\n",
    "#         showmeans = True,\n",
    "#         showmedians = True,\n",
    "#         quantiles = [ [ 0.01135, 0.5, 1. - 0.01135 ], ] * len( dists[param]['xs'] )\n",
    "    )\n",
    "    for i, poly in enumerate( v['bodies'] ):\n",
    "        poly.set_alpha( 0.5 )\n",
    "        poly.set_color( modeled_color, )\n",
    "    \n",
    "    # Plot MLEs\n",
    "    ax.scatter(\n",
    "        dists[param]['xs'],\n",
    "        dists[param]['mles'],\n",
    "        color = modeled_color,\n",
    "        s = 20,\n",
    "        edgecolor = 'w',\n",
    "        linewidth = 0.2,\n",
    "        zorder = 100,\n",
    "    )\n",
    "    \n",
    "    ax.set_ylabel( x_labels[param] )\n",
    "\n",
    "    tick_labels = [ _[1:] for _ in sl_keys ]\n",
    "    plt.xticks( ticks=main_xs, labels=tick_labels )\n",
    "    \n",
    "savefile = os.path.join( figure_dir, 'comparison.pdf' )\n",
    "print( 'Saving at {}'.format( savefile ) )\n",
    "plt.savefig( savefile, bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Summary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = verdict.Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For estimated data\n",
    "for param_key in dists.keys():\n",
    "    data_for_param = dists[param_key]\n",
    "    for i, mle in enumerate( data_for_param['mles'] ):\n",
    "        \n",
    "        if param_key[:3] == 'log':\n",
    "            param_key = param_key[3:]\n",
    "        \n",
    "        summary.setitem( 'estimated', mle, 'maximum likelihood estimate', param_key, data_for_param['sls'][i], data_for_param['comps'][i] )\n",
    "                \n",
    "        percentiles = {}\n",
    "        for p in [ 1, 5, 16, 25, 50 ]:\n",
    "            percentiles[helpers.percentile_str_fn(p/100.)] = np.nanpercentile( data_for_param['values'][i], p )\n",
    "            percentiles[helpers.percentile_str_fn(1. - p/100.)] = np.nanpercentile( data_for_param['values'][i], 100-p )\n",
    "        summary.setitem( 'estimated', percentiles, 'posterior percentiles', param_key, data_for_param['sls'][i], data_for_param['comps'][i], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_units  = {\n",
    "    'Density': u.g * u.cm**-3 / u.mp * 0.75,\n",
    "    'Temperature': u.K,\n",
    "    'Metallicity': 1 / Z_sun,\n",
    "    'HI Column': u.cm**-2,\n",
    "    'LOS Velocity': u.km / u.s,\n",
    "    'Lengths': u.cm,\n",
    "    'PDF Value': 1.,\n",
    "}\n",
    "synthetic_data_is_logscale = [ 'Density', 'Temperature', 'Metallicity', 'HI Column' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For source data\n",
    "for long_param_key in sls.keys():\n",
    "        \n",
    "    for sl in sl_keys:\n",
    "        \n",
    "        param_key = helpers.key_given_property[long_param_key]\n",
    "        \n",
    "        values = sls[long_param_key][int(sl)]\n",
    "        \n",
    "        if long_param_key in synthetic_data_is_logscale:\n",
    "            values = 10.**values\n",
    "        \n",
    "        values *= synthetic_data_units[long_param_key]\n",
    "        \n",
    "        if param_key in helpers.logscale_props:\n",
    "            values = np.log10( values )\n",
    "\n",
    "        summary.setitem( 'source', values, param_key, sl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_summary = verdict.Dict.from_hdf5( summary_data_fp, create_nonexistent=True )\n",
    "total_summary['sample1'] = summary\n",
    "total_summary.to_hdf5( summary_data_fp, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, 'Below is unnecessary. I will just use Sameers Plots.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot output spectra + fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objects for use\n",
    "ldb = trident.LineDatabase('lines.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Mg II lines\n",
    "ldb.add_line( 'Mg', 'II', 2796, use_linetools=True)\n",
    "ldb.add_line( 'Mg', 'II', 2803, use_linetools=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have the lower part of this Si IV doublet\n",
    "ldb.add_line( 'Si', 'IV', 1394, use_linetools=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_cos = trident.SpectrumGenerator('COS-G130M', line_database=ldb )\n",
    "sg_cos_160 = trident.SpectrumGenerator('COS-G160M', line_database=ldb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrum Generator for Mg II from ground\n",
    "lambda_mg = ldb.select_lines( 'Mg', 'II', 2796 )[0].wavelength * ( 1. + redshift )\n",
    "sg_mg = trident.SpectrumGenerator(\n",
    "    lambda_min = lambda_mg - 30.,\n",
    "    lambda_max = lambda_mg + 30.,\n",
    "    dlambda = 0.01,\n",
    "    lsf_kernel = os.path.join( trident.path, 'data', 'lsf_kernels', 'avg_COS.txt' ),\n",
    "    line_database = ldb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgs = [ sg_cos, sg_cos_160, sg_mg ]\n",
    "spectrum_sg_tags = [ '_G130', '_G160', '_MgII']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_sl = indices[i]\n",
    "sl_key = sl_keys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = sgs[j]\n",
    "spectrum_tag = spectrum_sg_tags[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_file = 'spectrum{}_sl{:04d}.h5'.format( spectrum_tag, ind_sl )\n",
    "spectrum_fp = os.path.join( observer_data_dir, spectrum_file )\n",
    "spectrum = verdict.Dict.from_hdf5( spectrum_fp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotted_ion = plotted_ions[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ions = ldb.parse_subset( plotted_ion )\n",
    "assert len( selected_ions ) == 1, 'Too many or too few possible ions.'\n",
    "selected_ion = selected_ions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_p_1 = spectrum['wavelength'] / ( 1. + redshift ) / selected_ion.wavelength\n",
    "vs_spec = ( u.c * ( z_p_1**2. - 1. ) / ( z_p_1**2. + 1. ) ).to( 'km/s' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_range = ( vs_spec > velocity_range[0] * u.km / u.s ) & ( vs_spec < velocity_range[1] * u.km / u.s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(\n",
    "    vs_spec,\n",
    "    spectrum['flux'],\n",
    "    color = 'k',\n",
    ")\n",
    "\n",
    "ax.annotate(\n",
    "    text = plotted_ion,\n",
    "    xy = ( 0, 0 ),\n",
    "    xytext = ( 5, 5 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    textcoords = 'offset points',\n",
    "    va = 'bottom', \n",
    "    ha = 'left',\n",
    ")\n",
    "\n",
    "ax.set_xlim( velocity_range )\n",
    "ax.set_ylim( 0, 1.1 )\n",
    "\n",
    "ax.set_xlabel( 'velocity [km/s]' )\n",
    "ax.set_ylabel( 'flux' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get estimated cloud properties\n",
    "clouds_estimated = summary['estimated']['maximum likelihood estimate']\n",
    "clouds_estimated = clouds_estimated.inner_item( sl_key )\n",
    "clouds_estimated = clouds_estimated.apply( verdict.Dict.array )\n",
    "\n",
    "# # Sort by T\n",
    "# sort_inds_estimated = np.argsort( clouds_estimated['T'] )\n",
    "# clouds_estimated = clouds_estimated.inner_item( sort_inds_estimated )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get source cloud properties\n",
    "clouds_source = summary['source'].inner_item( sl_key )\n",
    "\n",
    "# # Sort by T\n",
    "# sort_inds_source = np.argsort( clouds_source['T'] )\n",
    "# clouds_source = clouds_source.inner_item( sort_inds_source )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cloud = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cloud_source = np.argmin( np.abs( clouds_estimated['T'][i_cloud] - clouds_source['T'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_estimated = 10.**clouds_estimated['nH'][i_cloud] * u.cm**-3.,\n",
    "density_estimated *= ( u.mp / 0.75 )\n",
    "density_estimated = density_estimated.to( 'g/cm**3' )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a one-zone dataset for our desired density,\n",
    "# temperature, metallicity, and redshift.  We'll arbitrarily set it to\n",
    "# be 1 kpc in width.  \n",
    "test_ds = trident.make_onezone_dataset(\n",
    "    density = density_estimated,\n",
    "    temperature = 10.**clouds_estimated['T'][i_cloud] * u.K,\n",
    "    metallicity = 10.**clouds_estimated['Z'][i_cloud] * u.Zsun,\n",
    "    domain_width = 1.*u.kpc\n",
    ")\n",
    "test_ds.current_redshift = redshift\n",
    "\n",
    "# Now let's add our desired ions to this dataset, using Trident's \n",
    "# lookup table based on the Haardt-Madau 2012 UV background.\n",
    "trident.add_ion_fields( test_ds, ions=ions )\n",
    "\n",
    "# Since we now know the HI number density for this dataset, and we\n",
    "# have a desired HI column density from above (i.e., a LLS), we can divide \n",
    "# these two to get a desired length for the dataset.\n",
    "HI_column = 10.**clouds_source['NHI'][i_cloud_source] * u.cm**-2.\n",
    "length = HI_column / test_ds.r[('gas', 'H_p0_number_density')][0]\n",
    "\n",
    "ray = trident.make_onezone_ray(\n",
    "    density = density_estimated,\n",
    "    temperature = 10.**clouds_estimated['T'][i_cloud] * u.K,\n",
    "    metallicity = 10.**clouds_estimated['Z'][i_cloud] * u.Zsun,\n",
    "    length = length,\n",
    "    redshift = redshift,\n",
    ")\n",
    "trident.add_ion_fields( ray, ions=ions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.make_spectrum( ray )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
