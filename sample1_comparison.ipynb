{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import h5py\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.interpolate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Currently need to call this to get matplotlib selected style to load...\n",
    "plt.plot()\n",
    "matplotlib.style.use( '/Users/zhafen/repos/clean-bold/clean-bold-mnras.mplstyle' )\n",
    "import palettable\n",
    "import matplotlib.patheffects as path_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import trident\n",
    "import unyt as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kalepy as kale\n",
    "import verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "seed = 15482\n",
    "rng = np.random.default_rng( seed )\n",
    "verbose = False\n",
    "Z_sun = 0.014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management parameters\n",
    "distribution_fp = './data/EAGLE/histogram_galaxies_logM200c-Msun-12.0-12.5_200_seed0_hneutralssh.hdf5'\n",
    "data_dir = './data/synthetic_data/sample1'\n",
    "observer_data_dir = './data/synthetic_data_samples/sample1'\n",
    "summary_data_fp = './data/polished_data/summary.h5'\n",
    "figure_dir = '/Users/zhafen/drafts/cgm_modeling_challenge_paper/figures/sample1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs( figure_dir, exist_ok=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray parameters\n",
    "redshift = 0.25\n",
    "n_sightlines = 100\n",
    "min_clouds_per_sightline = 1\n",
    "max_clouds_per_sightline = 3\n",
    "velocity_range = [ -150., 150. ] # In km/s\n",
    "finite_cloud_max_logT = 5 # We'll only allow one cloud per line of sight with temperatures greater than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectra parameters\n",
    "ions = [\n",
    "    'H I',\n",
    "    'O I',\n",
    "    'C II',\n",
    "    'C III',\n",
    "    'N II',\n",
    "    'N III',\n",
    "    'Si II',\n",
    "    'Si III',\n",
    "    'Si IV',\n",
    "#     'N V',\n",
    "    'O VI',\n",
    "    'Mg II'\n",
    "]\n",
    "fields = [\n",
    "    'H_p0_number_density', \n",
    "    'O_p0_number_density',\n",
    "    'C_p1_number_density',\n",
    "    'C_p2_number_density',\n",
    "    'N_p1_number_density',\n",
    "    'N_p2_number_density',\n",
    "    'Si_p1_number_density',\n",
    "    'Si_p2_number_density',\n",
    "    'Si_p3_number_density',\n",
    "#     'N_p4_number_density',\n",
    "    'O_p5_number_density',\n",
    "    'Mg_p1_number_density'\n",
    "]\n",
    "snr = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "colors = palettable.cartocolors.qualitative.Safe_10.mpl_colors\n",
    "modeled_color = palettable.cartocolors.qualitative.Safe_10.mpl_colors[1]\n",
    "revised_color = palettable.cartocolors.qualitative.Safe_10.mpl_colors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled_data_dir = './data/modeling_results/sameer_charlton/sample1/pdfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a dictionary\n",
    "modeled = {}\n",
    "for dirname in tqdm.tqdm( os.listdir( modeled_data_dir ) ):\n",
    "        \n",
    "    # Get dirs, skip others\n",
    "    current_dir = os.path.join( modeled_data_dir, dirname )\n",
    "    if not os.path.isdir( current_dir ):\n",
    "        continue\n",
    "        \n",
    "    modeled_dir = {}\n",
    "    for file in os.listdir( current_dir ):\n",
    "        comp_key = file.split( '.' )[0]\n",
    "        \n",
    "        fp = os.path.join( current_dir, file )\n",
    "        df = pd.read_csv( fp, sep=' ', header=None, )\n",
    "        df.columns = [ 'Prob', 'Likelihood', 'logZ', 'logT', 'lognH' ]\n",
    "        \n",
    "        modeled_dir[comp_key] = df\n",
    "        \n",
    "    modeled[dirname[:3]] = modeled_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate histograms, and store in a format conducive to plotting\n",
    "sl_keys = sorted( list( modeled.keys() ) )\n",
    "params = [ 'logZ', 'logT', 'lognH' ]\n",
    "dx = 0.0\n",
    "dists = {}\n",
    "for param in params:\n",
    "    \n",
    "    param_dists = {\n",
    "        'xs': [],\n",
    "        'values': [],\n",
    "        'mles': [],\n",
    "        'sls': [],\n",
    "        'comps': [],\n",
    "    }\n",
    "    for i, sl in enumerate( tqdm.tqdm( sl_keys ) ):\n",
    "        \n",
    "        for j, ( comp_key, df ) in enumerate( modeled[sl].items() ):\n",
    "            \n",
    "            values = df[param].values\n",
    "            \n",
    "            x = i + j*dx\n",
    "            \n",
    "            kde = kale.kde.KDE( values )\n",
    "            centers, pdf = kde.density()\n",
    "            mle = centers[pdf.argmax()]\n",
    "            \n",
    "            param_dists['xs'].append( x )\n",
    "            param_dists['values'].append( values )\n",
    "            param_dists['mles'].append( mle )\n",
    "            param_dists['sls'].append( sl )\n",
    "            param_dists['comps'].append( comp_key )\n",
    "            \n",
    "    dists[param] = param_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of components\n",
    "n_comp_modeled = [ len( modeled[sl].keys() ) for sl in sl_keys ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sls = verdict.Dict.from_hdf5( './data/synthetic_data/sample1/sightlines.h5', jagged_flag='sl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = {}\n",
    "for key, item in sls.items():\n",
    "    clouds[key] = np.concatenate( item )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used sightlines\n",
    "indices = np.array( sl_keys ).astype( int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particular sightlines chosen\n",
    "combined = {\n",
    "    'logZ': [],\n",
    "    'logT': [],\n",
    "    'lognH': [],\n",
    "}\n",
    "for i in indices:\n",
    "    \n",
    "    print( 'Sightline {:03d}'.format( i ) )\n",
    "\n",
    "    density = 10.**sls['Density'][i] * u.g * u.cm**-3 / u.mp * 0.75\n",
    "    temperature = 10.**sls['Temperature'][i] * u.K\n",
    "    metallicity = 10.**sls['Metallicity'][i] / Z_sun\n",
    "    HI_column = 10.**sls['HI Column'][i] * u.cm**-2\n",
    "    velocity = sls['LOS Velocity'][i] * u.km / u.s\n",
    "    lengths = sls['Lengths'][i] * u.cm\n",
    "    \n",
    "    for j, den in enumerate( density ):\n",
    "        \n",
    "        print( '    logZ = {:.3g}, logT = {:.3g}, logn = {:.3g}'.format( \n",
    "                np.log10( metallicity[j] ),\n",
    "                np.log10( temperature[j] ),\n",
    "                np.log10( den ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if len( velocity ) == 2:\n",
    "        print( '    delta_v = {:.3g}'.format( np.abs( velocity[1] - velocity[0] ) ) )\n",
    "    \n",
    "    den = ( density * lengths ).sum() / lengths.sum()\n",
    "    temp = ( temperature * density * lengths ).sum() / ( density * lengths ).sum()\n",
    "    met = ( metallicity * Z_sun * density * lengths ).sum() / ( Z_sun * density * lengths ).sum()\n",
    "    print( '    Combined, logZ = {:.3g}, logT = {:.3g}, logn = {:.3g}'.format( \n",
    "            np.log10( met ),\n",
    "            np.log10( temp ),\n",
    "            np.log10( den ),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    combined['lognH'].append( den )\n",
    "    combined['logZ'].append( met )\n",
    "    combined['logT'].append( temp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_mapping = {\n",
    "    'logZ': 'Metallicity',\n",
    "    'logT': 'Temperature',\n",
    "    'lognH': 'Density',\n",
    "}\n",
    "x_labels = {\n",
    "    'logZ': r'$\\log_{10} Z / Z_\\odot$',\n",
    "    'logT': r'$\\log_{10} T / K$',\n",
    "    'lognH': r'$\\log_{10} n_{\\rm H} / {\\rm cm}^{-3}$',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_width = plt.rcParams['figure.figsize'][0]\n",
    "fig = plt.figure( figsize=( panel_width, panel_width*len( x_labels )/2. ), facecolor='w' )\n",
    "# ax_main = plt.gca()\n",
    "\n",
    "gs = matplotlib.gridspec.GridSpec( 3, 1 )\n",
    "# gs.update( hspace=0.1)\n",
    "\n",
    "main_xs = np.arange( len( indices ) )\n",
    "\n",
    "for i, param in enumerate( params ):\n",
    "    ax = fig.add_subplot( gs[i,0] )\n",
    "    \n",
    "#     # Combined\n",
    "#     ax.scatter(\n",
    "#         main_xs,\n",
    "#         np.log10( combined[param] ),\n",
    "#         color = 'none',\n",
    "#         edgecolor = 'k',\n",
    "#         s = 200,\n",
    "#         zorder = 100,\n",
    "#     )\n",
    "\n",
    "    # Individual clouds\n",
    "    for i, ind in enumerate( indices ):\n",
    "\n",
    "        if param == 'logZ':\n",
    "            ys = np.log10( 10.**sls[param_mapping[param]][ind] / Z_sun )\n",
    "        elif param == 'lognH':\n",
    "            ys = np.log10( 10.**sls[param_mapping[param]][ind] * u.g * u.cm**-3 / u.mp * 0.75 )\n",
    "        else:\n",
    "            ys = sls[param_mapping[param]][ind]\n",
    "\n",
    "        xs = np.full( ys.size, i )\n",
    "        ax.scatter(\n",
    "            xs,\n",
    "            ys,\n",
    "            color = 'k',\n",
    "            zorder = 90,\n",
    "            edgecolor = 'k',\n",
    "            linewidth = 0.2,\n",
    "            s = 25,\n",
    "        )\n",
    "        \n",
    "        ax.annotate(\n",
    "            text = '{}'.format( ys.size ),\n",
    "            xy = (i, 1),\n",
    "            xycoords = matplotlib.transforms.blended_transform_factory( ax.transData, ax.transAxes ),\n",
    "            xytext = ( -1, 2.5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'bottom',\n",
    "            ha = 'right',\n",
    "            fontsize = 'small',\n",
    "            fontweight = 'bold',\n",
    "        )\n",
    "    \n",
    "    # Annotate number of modeled components\n",
    "    ax.annotate(\n",
    "        text = r'$n_{\\rm comp}:$',\n",
    "        xy = ( 0, 1 ),\n",
    "        xycoords = 'axes fraction',\n",
    "        xytext = ( 0, 2.5 ),\n",
    "        textcoords = 'offset points',\n",
    "        fontsize = 'small',\n",
    "        va = 'bottom',\n",
    "        ha = 'right',\n",
    "        fontweight = 'bold',\n",
    "    )\n",
    "    for i, n_comp in enumerate( n_comp_modeled ): \n",
    "        ax.annotate(\n",
    "            text = '{}'.format( n_comp ),\n",
    "            xy = (i, 1),\n",
    "            xycoords = matplotlib.transforms.blended_transform_factory( ax.transData, ax.transAxes ),\n",
    "            xytext = ( 1, 2.5 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'bottom',\n",
    "            ha = 'left',\n",
    "            fontsize = 'small',\n",
    "            color = modeled_color,\n",
    "            fontweight = 'bold',\n",
    "        )\n",
    "        \n",
    "    # Violin plot\n",
    "    v = ax.violinplot(\n",
    "        dists[param]['values'],\n",
    "        dists[param]['xs'],\n",
    "        showextrema = False,\n",
    "        widths = 0.75,\n",
    "#         showmeans = True,\n",
    "#         showmedians = True,\n",
    "#         quantiles = [ [ 0.01135, 0.5, 1. - 0.01135 ], ] * len( dists[param]['xs'] )\n",
    "    )\n",
    "    for i, poly in enumerate( v['bodies'] ):\n",
    "        poly.set_alpha( 0.5 )\n",
    "        poly.set_color( modeled_color, )\n",
    "    \n",
    "    # Plot MLEs\n",
    "    ax.scatter(\n",
    "        dists[param]['xs'],\n",
    "        dists[param]['mles'],\n",
    "        color = modeled_color,\n",
    "        s = 20,\n",
    "        edgecolor = 'w',\n",
    "        linewidth = 0.2,\n",
    "        zorder = 100,\n",
    "    )\n",
    "    \n",
    "    ax.set_ylabel( x_labels[param] )\n",
    "\n",
    "    tick_labels = [ _[1:] for _ in sl_keys ]\n",
    "    plt.xticks( ticks=main_xs, labels=tick_labels )\n",
    "    \n",
    "savefile = os.path.join( figure_dir, 'comparison.pdf' )\n",
    "print( 'Saving at {}'.format( savefile ) )\n",
    "plt.savefig( savefile, bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Summary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = verdict.Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For estimated data\n",
    "for param_key in dists.keys():\n",
    "    data_for_param = dists[param_key]\n",
    "    for i, mle in enumerate( data_for_param['mles'] ):\n",
    "        \n",
    "        if param_key[:3] == 'log':\n",
    "            param_key = param_key[3:]\n",
    "        \n",
    "        summary.setitem( 'estimated', mle, 'maximum likelihood estimate', param_key, data_for_param['sls'][i], data_for_param['comps'][i] )\n",
    "                \n",
    "        percentiles = {}\n",
    "        for p in [ 1, 5, 16, 25, 50 ]:\n",
    "            percentiles[helpers.percentile_str_fn(p/100.)] = np.nanpercentile( data_for_param['values'][i], p )\n",
    "            percentiles[helpers.percentile_str_fn(1. - p/100.)] = np.nanpercentile( data_for_param['values'][i], 100-p )\n",
    "        summary.setitem( 'estimated', percentiles, 'posterior percentiles', param_key, data_for_param['sls'][i], data_for_param['comps'][i], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_units  = {\n",
    "    'Density': u.g * u.cm**-3 / u.mp * 0.75,\n",
    "    'Temperature': u.K,\n",
    "    'Metallicity': 1 / Z_sun,\n",
    "    'HI Column': u.cm**-2,\n",
    "    'LOS Velocity': u.km / u.s,\n",
    "    'Lengths': u.cm,\n",
    "    'PDF Value': 1.,\n",
    "}\n",
    "synthetic_data_is_logscale = [ 'Density', 'Temperature', 'Metallicity', 'HI Column' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For source data\n",
    "for long_param_key in sls.keys():\n",
    "        \n",
    "    for sl in sl_keys:\n",
    "        \n",
    "        param_key = helpers.key_given_property[long_param_key]\n",
    "        \n",
    "        values = sls[long_param_key][int(sl)]\n",
    "        \n",
    "        if long_param_key in synthetic_data_is_logscale:\n",
    "            values = 10.**values\n",
    "        \n",
    "        values *= synthetic_data_units[long_param_key]\n",
    "        \n",
    "        if param_key in helpers.logscale_props:\n",
    "            values = np.log10( values )\n",
    "\n",
    "        summary.setitem( 'source', values, param_key, sl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_summary = verdict.Dict.from_hdf5( summary_data_fp, create_nonexistent=True )\n",
    "total_summary['sample1'] = summary\n",
    "total_summary.to_hdf5( summary_data_fp, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
