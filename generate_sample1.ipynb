{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import h5py\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import scipy.interpolate\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt\n",
    "import trident\n",
    "import unyt as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kalepy as kale\n",
    "import verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import one_zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "seed = 15482\n",
    "np.random.seed( seed )\n",
    "rng = np.random.default_rng( seed )\n",
    "load_existing_sightlines = True\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management parameters\n",
    "distribution_fp = './data/EAGLE/histogram_galaxies_logM200c-Msun-12.0-12.5_200_seed0_hneutralssh.hdf5'\n",
    "data_dir = './data/synthetic_data/sample1'\n",
    "observer_data_dir = './data/synthetic_data_samples/sample1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray parameters\n",
    "redshift = 0.25\n",
    "n_sightlines = 100\n",
    "min_clouds_per_sightline = 1\n",
    "max_clouds_per_sightline = 3\n",
    "velocity_range = [ -150., 150. ] # In km/s\n",
    "finite_cloud_max_logT = 5 # We'll only allow one cloud per line of sight with temperatures greater than this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectra parameters\n",
    "ions = [\n",
    "    'H I',\n",
    "    'O I',\n",
    "    'C II',\n",
    "    'C III',\n",
    "    'C IV',\n",
    "    'N II',\n",
    "    'N III',\n",
    "    'Si II',\n",
    "    'Si III',\n",
    "    'Si IV',\n",
    "    'N V',\n",
    "    'O VI',\n",
    "    'Mg II'\n",
    "]\n",
    "fields = [\n",
    "    'H_p0_number_density', \n",
    "    'O_p0_number_density',\n",
    "    'C_p1_number_density',\n",
    "    'C_p2_number_density',\n",
    "    'C_p3_number_density',\n",
    "    'N_p1_number_density',\n",
    "    'N_p2_number_density',\n",
    "    'Si_p1_number_density',\n",
    "    'Si_p2_number_density',\n",
    "    'Si_p3_number_density',\n",
    "    'N_p4_number_density',\n",
    "    'O_p5_number_density',\n",
    "    'Mg_p1_number_density'\n",
    "]\n",
    "snr = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Format Data\n",
    "\n",
    "Units are [ g/cm^3, mass fraction, logK, log cm^-2 ] respectively for ['Density', 'Metallicity', 'Temperature', 'hneutralssh']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File( distribution_fp, 'r' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centers, reformat edges\n",
    "\n",
    "histogram_axes = [ 'Temperature', 'Density', 'Metallicity', 'hneutralssh' ]\n",
    "centers = []\n",
    "bins = []\n",
    "dxs = []\n",
    "for i, key in enumerate( histogram_axes ):\n",
    "    \n",
    "    arr = copy.copy( f['histogram_axes'][key][...] )\n",
    "    dx = arr[2] - arr[1]\n",
    "    \n",
    "    # For convenience, let's not have a -inf edge lying around\n",
    "    if key == 'Metallicity':\n",
    "        arr[0] = arr[1] - dx\n",
    "        \n",
    "    centers_i = arr[:-1] + 0.5 * dx\n",
    "    \n",
    "    dxs.append( dx )\n",
    "    centers.append( centers_i )\n",
    "    bins.append( arr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize into a pdf\n",
    "\n",
    "norm = f['histogram'][...].sum() * dxs[0] * dxs[1] * dxs[2] * dxs[3]\n",
    "pdf = f['histogram'][...] / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Ways to Sample the Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Kernel Density Estimate to Allow Easy Resampling\n",
    "kde = kale.KDE.from_hist(\n",
    "    bins,\n",
    "    pdf,\n",
    "    reflect = [\n",
    "        None,\n",
    "        None,\n",
    "        [ None, 0. ],\n",
    "        None,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interpolation function\n",
    "def prob_fn( temp, den, met, hi ):\n",
    "    \n",
    "    return scipy.interpolate.interpn( centers, pdf, [ temp, den, met, hi ] )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the peak\n",
    "max_ind = np.argmax( pdf, )\n",
    "max_inds = np.unravel_index( max_ind, f['histogram'][...].shape )\n",
    "max_value = np.max( pdf )\n",
    "p0 = tuple( [ centers[i][max_inds[i]] for i in range( len( max_inds ) ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check work\n",
    "print( 'If these two values are consistent then interpolation is working correctly.' )\n",
    "print( '    max value = {:.3g}, max interpolated value = {:.3g}'.format( max_value, prob_fn( *p0 ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Sightline Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_labels = [ 'Temperature', 'Density', 'Metallicity', 'HI Column' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_existing_sightlines:\n",
    "    sls = verdict.Dict.from_hdf5( './data/synthetic_data/sample1/sightlines.h5', jagged_flag='sl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_existing_sightlines:\n",
    "    sls = {\n",
    "        'Temperature': [],\n",
    "        'Density': [],\n",
    "        'Metallicity': [],\n",
    "        'HI Column': [],\n",
    "        'LOS Velocity': [],\n",
    "        'PDF Value': [],\n",
    "    }\n",
    "    for i in tqdm.tqdm( range( n_sightlines ) ):\n",
    "\n",
    "        # Choose number of clouds\n",
    "        n_clouds = rng.integers( min_clouds_per_sightline, max_clouds_per_sightline+1 )\n",
    "\n",
    "        n_hot = 0\n",
    "        n_clouds_in_sample = 0\n",
    "        sample = []\n",
    "        while n_clouds_in_sample < n_clouds:\n",
    "            # Sample from distribution\n",
    "            cloud_i = kde.resample( 1 ).transpose()[0]\n",
    "\n",
    "            # Only allow up to one hot cloud per sightline\n",
    "            if cloud_i[0] > finite_cloud_max_logT:\n",
    "                if n_hot > 0:\n",
    "                    continue\n",
    "                n_hot += 1\n",
    "\n",
    "            sample.append( cloud_i )\n",
    "            n_clouds_in_sample += 1\n",
    "        sample = np.array( sample ).transpose()\n",
    "\n",
    "        # Store parameters\n",
    "        for i, param in enumerate( param_labels ):\n",
    "            sls[param].append( sample[i] )\n",
    "\n",
    "        # Choose velocities\n",
    "        sls['LOS Velocity'].append( rng.uniform( *velocity_range, size=n_clouds ) )\n",
    "\n",
    "        # Identify frequency in simulations\n",
    "        sls['PDF Value'].append( np.array([ prob_fn( *_ ) for _ in sample.transpose() ]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = {}\n",
    "for key, item in sls.items():\n",
    "    clouds[key] = np.concatenate( item )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up combinations to iterate through\n",
    "inds = range( len( histogram_axes ) )\n",
    "combinations = [ _ for _ in itertools.combinations( inds, 2 ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ 'Temperature (K)', r'Density (g/cm$^{3}$)', 'Metallicity (mass fraction)', r'$N_{\\rm HI}$ (cm$^{-2}$)' ]\n",
    "for k, (i, j) in enumerate( combinations ):\n",
    "    \n",
    "    # Show data\n",
    "    fig = plt.figure( figsize=(8,8), facecolor='w' )\n",
    "    ax = plt.gca()\n",
    "\n",
    "    sum_axes = copy.copy( list( inds ) )\n",
    "    sum_axes.remove( i )\n",
    "    sum_axes.remove( j )\n",
    "    projection = pdf.sum( axis=tuple( sum_axes ) ).transpose()\n",
    "    x, y = np.meshgrid( centers[i], centers[j] )\n",
    "    ax.pcolormesh(\n",
    "        centers[i],\n",
    "        centers[j],\n",
    "        np.log10( projection ),\n",
    "        cmap = 'cubehelix_r',\n",
    "    )\n",
    "    \n",
    "    ax.scatter(\n",
    "        clouds[param_labels[i]],\n",
    "        clouds[param_labels[j]],\n",
    "        edgecolor = 'k',\n",
    "        s = 100,\n",
    "        c = clouds['PDF Value'],\n",
    "        vmin = np.nanmin( pdf[np.nonzero(pdf)] ),\n",
    "        vmax = np.nanmax( pdf[np.nonzero(pdf)] ),\n",
    "        cmap = palettable.cubehelix.classic_16_r.mpl_colormap,\n",
    "        norm = matplotlib.colors.LogNorm(),\n",
    "    )\n",
    "\n",
    "    \n",
    "    ax.set_xlabel( labels[i], fontsize=22 )\n",
    "    ax.set_ylabel( labels[j], fontsize=22 )\n",
    "    \n",
    "    ax.set_aspect( 'auto' )\n",
    "    \n",
    "    plt.savefig(\n",
    "        './figures/sample1/clouddist_{}_{}.png'.format(\n",
    "            param_labels[i].replace( ' ', '' ),\n",
    "            param_labels[j].replace( ' ', '' )\n",
    "        ),\n",
    "        bbox_inches = 'tight',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D histograms\n",
    "for i, param_label in enumerate( param_labels ):\n",
    "    \n",
    "    fig = plt.figure( figsize=(10,4), facecolor='w' )\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    sum_axes = copy.copy( list( inds ) )\n",
    "    sum_axes.remove( i )\n",
    "    projection = pdf.sum( axis=tuple( sum_axes ) )\n",
    "    projection /= projection.sum() * dxs[i]\n",
    "    \n",
    "    ax.step(\n",
    "        centers[i],\n",
    "        projection,\n",
    "        where = 'mid',\n",
    "        color = 'k',\n",
    "        linewidth = 3,\n",
    "    )\n",
    "    \n",
    "    # For convenience, let's not have a -inf edge lying around\n",
    "    used_bins = copy.copy( bins[i] )\n",
    "    if param_label == 'Metallicity':\n",
    "        used_bins[-1] = 1.0001\n",
    "    \n",
    "    hist, used_bins = np.histogram(\n",
    "        clouds[param_labels[i]],\n",
    "        bins = used_bins,\n",
    "    )\n",
    "    hist =  hist / ( hist.sum() * dxs[i] )\n",
    "    ax.step(\n",
    "        used_bins[1:],\n",
    "        hist,\n",
    "        where = 'pre',\n",
    "        color = palettable.cartocolors.qualitative.Safe_10.mpl_colors[1],\n",
    "        linewidth = 3,\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel( labels[i], fontsize=20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spectra\n",
    "\n",
    "Borrowing heavily from `one_zone.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objects for use\n",
    "ldb = trident.LineDatabase('lines.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Mg II lines\n",
    "ldb.add_line( 'Mg', 'II', 2796, use_linetools=True)\n",
    "ldb.add_line( 'Mg', 'II', 2803, use_linetools=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have the lower part of this Si IV doublet\n",
    "ldb.add_line( 'Si', 'IV', 1394, use_linetools=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_cos = trident.SpectrumGenerator('COS-G130M', line_database=ldb )\n",
    "sg_cos_160 = trident.SpectrumGenerator('COS-G160M', line_database=ldb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrum Generator for Mg II from ground\n",
    "lambda_mg = ldb.select_lines( 'Mg', 'II', 2796 )[0].wavelength * ( 1. + redshift )\n",
    "sg_mg = trident.SpectrumGenerator(\n",
    "    lambda_min = lambda_mg - 30.,\n",
    "    lambda_max = lambda_mg + 30.,\n",
    "    dlambda = 0.01,\n",
    "    lsf_kernel = os.path.join( trident.path, 'data', 'lsf_kernels', 'avg_COS.txt' ),\n",
    "    line_database = ldb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ion( sg, element, ion_state, width=6. ):\n",
    "    '''Save a plot of a particular part of the spectrum for inspection.'''\n",
    "    \n",
    "    lines = ldb.select_lines( element, ion_state )\n",
    "    \n",
    "    wavelengths = np.array([ _.wavelength for _ in lines ])\n",
    "    adjusted_wavelengths = wavelengths * ( 1 + redshift )\n",
    "    \n",
    "    data_subdir = '{}/ion_spectra/{}{}'.format( data_dir, element, ion_state, )\n",
    "    os.makedirs( data_subdir, exist_ok=True )\n",
    "    for k, lambda_a in enumerate( adjusted_wavelengths ):\n",
    "        if lambda_a - width/2. < sg.lambda_min or lambda_a + width/2 > sg.lambda_max:\n",
    "            continue\n",
    "            \n",
    "        sg.plot_spectrum(\n",
    "            '{}/spectrum_{:.1f}_sl{:04d}.png'.format( data_subdir, lambda_a, i ),\n",
    "            lambda_limits = [ lambda_a - width/2, lambda_a + width/2 ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waaaay too much output otherwise\n",
    "yt.utilities.logger.disable_stream_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over and create all spectra\n",
    "sls['Lengths'] = []\n",
    "spectrum_sg_tags = [ '_G130', '_G160', '_MgII']\n",
    "for i in tqdm.tqdm( range( n_sightlines ) ):\n",
    "    \n",
    "    for m, sg in enumerate( [ sg_cos, sg_cos_160, sg_mg ]):\n",
    "\n",
    "        density = 10.**sls['Density'][i] * u.g * u.cm**-3\n",
    "        temperature = 10.**sls['Temperature'][i] * u.K\n",
    "        metallicity = 10.**sls['Metallicity'][i] * u.Zsun / 0.014\n",
    "        HI_column = 10.**sls['HI Column'][i] * u.cm**-2\n",
    "        velocity = sls['LOS Velocity'][i] * u.km / u.s\n",
    "\n",
    "        os.makedirs( os.path.join( data_dir, 'clouds' ), exist_ok=True )\n",
    "        spectrum_fps = [\n",
    "            '{}/clouds/spectrum_sl{:04d}_cloud{:02d}.h5'.format( data_dir, i, j )\n",
    "            for j in range( density.size )\n",
    "        ]\n",
    "\n",
    "        lengths_i = []\n",
    "        taus_i = []\n",
    "        for j, density_j in enumerate( density ):\n",
    "\n",
    "            # First, let's create a one-zone dataset for our desired density,\n",
    "            # temperature, metallicity, and redshift.  We'll arbitrarily set it to\n",
    "            # be 1 kpc in width.  \n",
    "            ds = trident.make_onezone_dataset(\n",
    "                density = density[j],\n",
    "                temperature = temperature[j],\n",
    "                metallicity = metallicity[j],\n",
    "                domain_width = 1.*u.kpc\n",
    "            )\n",
    "            ds.current_redshift = redshift\n",
    "\n",
    "            # Now let's add our desired ions to this dataset, using Trident's \n",
    "            # lookup table based on the Haardt-Madau 2012 UV background.\n",
    "            trident.add_ion_fields(ds, ions=ions, line_database=ldb)\n",
    "\n",
    "            # Since we now know the HI number density for this dataset, and we\n",
    "            # have a desired HI column density from the simulation distribution, we can divide \n",
    "            # these two to get a desired length for the dataset.\n",
    "            length = HI_column[j] / ds.r[('gas', 'H_p0_number_density')][0]\n",
    "            lengths_i.append( length )\n",
    "\n",
    "            if verbose:\n",
    "                print(\"DEBUG: For a log HI column of %s, we require a Pathlength of %s\" % \n",
    "                        (np.log10(HI_column[i]), length.to('kpc')))\n",
    "\n",
    "            if verbose:\n",
    "                # Print out the dataset to STDOUT\n",
    "                one_zone.print_dataset(ray, ions, fields)\n",
    "\n",
    "            # Correct the redshift\n",
    "            z_vel = np.sqrt( ( 1 + velocity[j] / u.c) / ( 1 - velocity[j] / u.c) ) - 1.\n",
    "            z_cloud = ( 1. + redshift )*( 1. + z_vel ) - 1.\n",
    "\n",
    "            # Now that we have a length for our dataset, which will produce our \n",
    "            # desired HI column density, let's generate a one-zone\n",
    "            # LightRay (skewer) using this length, density, temperature, & redshift.\n",
    "            # And add the relevant ions to this dataset.\n",
    "            ray = trident.make_onezone_ray(\n",
    "                density = density[j],\n",
    "                temperature = temperature[j],\n",
    "                metallicity = metallicity[j],\n",
    "                length = length,\n",
    "                redshift = z_cloud,\n",
    "            )\n",
    "            trident.add_ion_fields(ray, ions=ions, line_database=ldb)\n",
    "\n",
    "            sg.make_spectrum( ray, lines=ions, store_observables=True )\n",
    "            sg.save_spectrum( spectrum_fps[j] )\n",
    "            \n",
    "            observables = sg.line_observables_dict\n",
    "\n",
    "            d = verdict.Dict.from_hdf5( spectrum_fps[j] )\n",
    "            wavelength = d['wavelength']\n",
    "            taus_i.append( d['tau'] )\n",
    "\n",
    "        lengths_i = np.array( lengths_i )\n",
    "        if m == 0:\n",
    "            sls['Lengths'].append( lengths_i )\n",
    "        taus_i = np.array( taus_i )\n",
    "\n",
    "        # Combine into a new spectrum\n",
    "        tau_i = np.sum( taus_i, axis=0 )\n",
    "        flux_i = np.exp( -tau_i )\n",
    "        sg.load_spectrum( wavelength * u.Angstrom, tau_i, flux_i )\n",
    "\n",
    "        # Noise\n",
    "        sg.apply_lsf()\n",
    "        sg.add_gaussian_noise( snr )\n",
    "\n",
    "        # Save\n",
    "        sg.save_spectrum(\n",
    "            '{}/spectrum{}_sl{:04d}.h5'.format( observer_data_dir, spectrum_sg_tags[m], i )\n",
    "        )\n",
    "        sg.plot_spectrum(\n",
    "            '{}/spectrum{}_sl{:04d}.png'.format( observer_data_dir, spectrum_sg_tags[m], i )\n",
    "        )\n",
    "\n",
    "        # Plot individual ions for inspection\n",
    "        if m == 0:\n",
    "            for ion in ions:\n",
    "                plot_ion( sg, *ion.split() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Sightline Input\n",
    "\n",
    "Now that we also have the lengths of absorbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_existing_sightlines:\n",
    "    sls = verdict.Dict( sls )\n",
    "    sls.to_hdf5( './data/synthetic_data/sample1/sightlines.h5', handle_jagged_arrs='row datasets', jagged_flag='sl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
